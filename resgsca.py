import math
import os
import glob
import numpy as np
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler
from torchvision import transforms
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import KFold, StratifiedKFold
from tqdm import tqdm
from collections import Counter
import torch_optimizer as optim
import pandas as pd
import time
from model import CTModel
# ---- Training & Evaluation ----
def cross_validation(dataset, model_class, num_folds=10, epochs=100, batch_size=64, 
                    criterion=None, optimizer_fn=None, scheduler_fn=None, 
                    device=None, save_dir='./cv_checkpoints', 
                    verbose=True, stratified=True):
    """
    æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯
    
    å‚æ•°:
        dataset: æ•°æ®é›†
        model_class: æ¨¡å‹ç±»ï¼Œç”¨äºåˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
        num_folds: æŠ˜æ•°ï¼Œé»˜è®¤ä¸º10
        epochs: æ¯æŠ˜è®­ç»ƒçš„è½®æ•°
        batch_size: æ‰¹é‡å¤§å°
        criterion: æŸå¤±å‡½æ•°
        optimizer_fn: ä¼˜åŒ–å™¨å‡½æ•°ï¼Œæ¥å—model.parameters()ä½œä¸ºå‚æ•°
        scheduler_fn: å­¦ä¹ ç‡è°ƒåº¦å™¨å‡½æ•°ï¼Œæ¥å—optimizerä½œä¸ºå‚æ•°
        device: è®­ç»ƒè®¾å¤‡
        save_dir: ä¿å­˜æ¨¡å‹çš„ç›®å½•
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        stratified: æ˜¯å¦ä½¿ç”¨åˆ†å±‚æŠ½æ ·
    
    è¿”å›:
        ç»“æœå­—å…¸ï¼ŒåŒ…å«æ¯æŠ˜çš„è¯„ä¼°æŒ‡æ ‡å’Œå¹³å‡æŒ‡æ ‡
    """
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(save_dir, exist_ok=True)
    
    # å‡†å¤‡äº¤å‰éªŒè¯
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # è·å–æ‰€æœ‰æ ‡ç­¾ç”¨äºåˆ†å±‚æŠ½æ ·
    all_labels = [label for _, label in dataset]
    
    # é€‰æ‹©KæŠ˜äº¤å‰éªŒè¯æ–¹æ³•
    if stratified:
        kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)
        splits = kfold.split(np.arange(len(dataset)), all_labels)
    else:
        kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)
        splits = kfold.split(np.arange(len(dataset)))
    
    # å­˜å‚¨æ¯æŠ˜çš„ç»“æœ
    fold_results = []
    best_models = []
    
    # å¼€å§‹KæŠ˜äº¤å‰éªŒè¯
    for fold, (train_idx, val_idx) in enumerate(splits):
        print(f"\n{'='*20} Fold {fold+1}/{num_folds} {'='*20}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_sampler = SubsetRandomSampler(train_idx)
        val_sampler = SubsetRandomSampler(val_idx)
        
        train_loader = DataLoader(dataset, batch_size=batch_size, 
                                 sampler=train_sampler, num_workers=4)
        val_loader = DataLoader(dataset, batch_size=batch_size,
                               sampler=val_sampler, num_workers=4)
        
        # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
        model = model_class().to(device)
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = optimizer_fn(model.parameters()) if optimizer_fn else \
                   optim.Lookahead(optim.RAdam(model.parameters(), lr=1e-4))
        scheduler = scheduler_fn(optimizer) if scheduler_fn else \
                   torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        
        # è®­ç»ƒè·Ÿè¸ª
        best_f1 = 0.0
        fold_save_path = os.path.join(save_dir, f'fold_{fold+1}_best.pth')
        fold_metrics = []
        
        # è®­ç»ƒå¾ªç¯
        progress_bar = tqdm(range(epochs), desc=f"Fold {fold+1} Training", unit="epoch")
        for epoch in progress_bar:
            train_loss, acc, prec, rec, f1 = train(model, train_loader, val_loader, 
                                                  criterion, optimizer, scheduler, device)
            
            # è®°å½•æŒ‡æ ‡
            metrics = {
                'fold': fold + 1,
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'val_acc': acc,
                'val_prec': prec,
                'val_rec': rec,
                'val_f1': f1
            }
            fold_metrics.append(metrics)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_description(
                f"Fold {fold+1} | Epoch {epoch+1} | Loss: {train_loss:.4f} | "
                f"Acc: {acc:.4f} | F1: {f1:.4f}"
            )
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if f1 > best_f1:
                best_f1 = f1
                torch.save(model.state_dict(), fold_save_path)
                if verbose:
                    print(f"  ğŸ‰ New best F1: {best_f1:.4f}, saved to {fold_save_path}")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°
        model.load_state_dict(torch.load(fold_save_path))
        final_acc, final_prec, final_rec, final_f1 = evaluate(model, val_loader, device)
        
        # è®°å½•è¯¥æŠ˜çš„æœ€ç»ˆç»“æœ
        fold_result = {
            'fold': fold + 1,
            'acc': final_acc,
            'prec': final_prec,
            'rec': final_rec,
            'f1': final_f1
        }
        fold_results.append(fold_result)
        best_models.append((model, fold_save_path, final_f1))
        
        print(f"Fold {fold+1} Final Results: Acc={final_acc:.4f}, Prec={final_prec:.4f}, "
              f"Rec={final_rec:.4f}, F1={final_f1:.4f}")
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    avg_acc = sum(r['acc'] for r in fold_results) / num_folds
    avg_prec = sum(r['prec'] for r in fold_results) / num_folds
    avg_rec = sum(r['rec'] for r in fold_results) / num_folds
    avg_f1 = sum(r['f1'] for r in fold_results) / num_folds
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_model_idx = max(range(len(best_models)), key=lambda i: best_models[i][2])
    best_model, best_path, best_f1_score = best_models[best_model_idx]
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°æ€»ä½“æœ€ä½³è·¯å¾„
    overall_best_path = os.path.join(save_dir, 'overall_best.pth')
    torch.save(best_model.state_dict(), overall_best_path)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*50)
    print(f"Cross-Validation Complete - {num_folds} Folds")
    print(f"Average Metrics: Acc={avg_acc:.4f}, Prec={avg_prec:.4f}, "
          f"Rec={avg_rec:.4f}, F1={avg_f1:.4f}")
    print(f"Best Model from Fold {best_model_idx+1} with F1={best_f1_score:.4f}")
    print(f"Best Model saved to {overall_best_path}")
    print("="*50)
    
    # è¿”å›ç»“æœ
    return {
        'fold_results': fold_results,
        'avg_acc': avg_acc,
        'avg_prec': avg_prec,
        'avg_rec': avg_rec,
        'avg_f1': avg_f1,
        'best_model_fold': best_model_idx + 1,
        'best_model_path': overall_best_path,
        'best_f1': best_f1_score
    }

def evaluate(model, dataloader, device):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for imgs, labels in dataloader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            preds = outputs.argmax(dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    acc = accuracy_score(all_labels, all_preds)
    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)
    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    return acc, prec, rec, f1

def train(model, train_loader, val_loader, criterion, optimizer, scheduler, device):
    model.train()
    total_loss = 0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    scheduler.step()
    val_acc, val_prec, val_rec, val_f1 = evaluate(model, val_loader, device)
    return total_loss / len(train_loader), val_acc, val_prec, val_rec, val_f1

# ---- Dataset ----
class NpzPatchDataset(Dataset):
    def __init__(self, root_dirs, labels_map, transform=None):
        self.samples = []
        self.transform = transform
        for label, dir_path in root_dirs.items():
            for npz_path in glob.glob(os.path.join(dir_path, '*.npz')):
                self.samples.append((npz_path, labels_map[label]))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        npz_path, label = self.samples[idx]
        data = np.load(npz_path)
        img = data['data']  # (H,W,3)
        img = torch.from_numpy(img.transpose(2,0,1)).float() / 255.0
        #img = torch.from_numpy(img).float() / 255.0
        if self.transform:
            img = self.transform(img)
        return img, label
#-----Facol loss------
class FocalLoss(nn.Module):
    def __init__(self,
                 alpha=None,
                 gamma: float = 2.0,
                 reduction: str = 'mean',
                 ignore_index: int = -100):
        """
        alpha:         None æˆ–è€… shape=[num_classes] çš„ Tensor æˆ– floatï¼Œ
                       äºŒåˆ†ç±»æ—¶ float ä¼šè¢«è½¬æ¢ä¸º [alpha, 1-alpha] Tensor
        gamma:         èšç„¦ç³»æ•° Î³ï¼Œå…¸å‹å€¼ 2.0
        reduction:     'none' | 'mean' | 'sum'
        ignore_index:  å¿½ç•¥æ ‡ç­¾
        """
        super().__init__()
        # å¦‚æœæ˜¯å•ä¸€ floatï¼ˆç”¨äºäºŒåˆ†ç±»ï¼‰ï¼Œè½¬æ¢ä¸º [Î±, 1âˆ’Î±] Tensor
        if isinstance(alpha, float):
            self.alpha = torch.tensor([alpha, 1.0 - alpha], dtype=torch.float32)
        else:
            self.alpha = alpha  # None æˆ– å·²ç»æ˜¯ Tensor
        self.gamma = gamma
        self.reduction = reduction
        self.ignore_index = ignore_index

    def forward(self, inputs, targets):
        """
        inputs:  [N, C] logits æˆ–è€… [N] logitsï¼ˆäºŒåˆ†ç±»ï¼‰
        targets: [N] LongTensor
        """
        # äºŒåˆ†ç±»åˆ†æ”¯
        if inputs.dim() == 1 or inputs.size(1) == 1:
            logits = inputs.view(-1)
            targets = targets.view(-1).float()
            bce_loss = F.binary_cross_entropy_with_logits(
                logits, targets, reduction='none')
            pt = torch.exp(-bce_loss)  # pt = sigmoid(logit) æˆ– 1âˆ’pt
            if self.alpha is not None:
                # å¯¹äºŒåˆ†ç±» alpha å¼ é‡å¹¿æ’­
                alpha_factor = (targets * self.alpha[0] +
                                (1 - targets) * self.alpha[1]).to(bce_loss.device)
                loss = alpha_factor * (1 - pt) ** self.gamma * bce_loss
            else:
                loss = (1 - pt) ** self.gamma * bce_loss

        # å¤šåˆ†ç±»åˆ†æ”¯
        else:
            logp = F.log_softmax(inputs, dim=1)     # [N, C] :contentReference[oaicite:0]{index=0}
            p = torch.exp(logp)                     # [N, C]
            # å–å¯¹åº”ç±»åˆ«çš„ log p_t å’Œ p_t
            targets = targets.view(-1, 1)
            logpt = logp.gather(1, targets).view(-1)
            pt = p.gather(1, targets).view(-1)
            # å‡†å¤‡ Î±_t
            if self.alpha is not None:
                # ç¡®ä¿ Î± æ˜¯ Tensor å¹¶åœ¨åŒ device
                if not isinstance(self.alpha, torch.Tensor):
                    raise ValueError("alpha must be Tensor for multiclass")
                at = self.alpha.to(inputs.device).gather(0, targets.view(-1))
            else:
                at = 1.0
            loss = -at * (1 - pt) ** self.gamma * logpt

        # å¿½ç•¥ç‰¹å®šæ ‡ç­¾
        if self.ignore_index >= 0:
            valid = targets.view(-1) != self.ignore_index
            loss = loss[valid]

        # Reduction
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:
            return loss
                 
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='ResGSCA Training')
    parser.add_argument('--data_dir', type=str, default='./database/3slice/48', help='Data directory')
    parser.add_argument('--batch_size', type=int, default=128, help='Batch size')
    parser.add_argument('--epochs', type=int, default=150, help='Number of epochs')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--save_dir', type=str, default='./resgsca_checkpoint/32', help='Directory to save checkpoints')
    parser.add_argument('--device', type=str, default=None, help='Device to use (cuda or cpu)')
    parser.add_argument('--cv', action='store_true', help='Use cross-validation')
    parser.add_argument('--folds', type=int, default=10, help='Number of folds for cross-validation')
    parser.add_argument('--stratified', action='store_true', help='Use stratified sampling for cross-validation')
    parser.add_argument('--cv_save_dir', type=str, default='./cv_checkpoints', help='Directory to save cross-validation checkpoints')
    parser.add_argument('--seed', type=int, default=42, help='Random seed')
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    if args.device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    if args.cv:
        os.makedirs(args.cv_save_dir, exist_ok=True)
    
    # æ•°æ®ç›®å½•å’Œæ ‡ç­¾æ˜ å°„
    root_dirs = {
        'cancer': os.path.join(args.data_dir, 'cancer'),
        'nocancer': os.path.join(args.data_dir, 'nocancer'),
    }
    labels_map = {'cancer': 1, 'nocancer': 0}
    
    # æ•°æ®å¢å¼º
    transform = transforms.Compose([
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.5),
    ])
    
    # åŠ è½½æ•°æ®é›†
    full_dataset = NpzPatchDataset(root_dirs, labels_map, transform)
    
    # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ
    label_list = [label for _, label in full_dataset]
    print("æ ‡ç­¾åˆ†å¸ƒ:", Counter(label_list))
    
    # å†³å®šæ˜¯å¦ä½¿ç”¨äº¤å‰éªŒè¯
    if args.cv:
        print(f"\n{'='*20} å¼€å§‹ {args.folds} æŠ˜äº¤å‰éªŒè¯ {'='*20}")
        start_time = time.time()
        
        # å®šä¹‰ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨åˆ›å»ºå‡½æ•°
        def create_optimizer(params):
            return optim.Lookahead(optim.RAdam(params, lr=args.lr))
        
        def create_scheduler(optimizer):
            return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)
        
        # æ‰§è¡Œäº¤å‰éªŒè¯
        cv_results = cross_validation(
            dataset=full_dataset,
            model_class=CTModel,
            num_folds=args.folds,
            epochs=args.epochs,
            batch_size=args.batch_size,
            criterion=FocalLoss(alpha=0.25, gamma=2.0),
            optimizer_fn=create_optimizer,
            scheduler_fn=create_scheduler,
            device=device,
            save_dir=args.cv_save_dir,
            stratified=args.stratified
        )
        
        # ä¿å­˜äº¤å‰éªŒè¯ç»“æœåˆ°CSV
        results_df = pd.DataFrame(cv_results['fold_results'])
        results_csv_path = os.path.join(args.cv_save_dir, 'cv_results.csv')
        results_df.to_csv(results_csv_path, index=False)
        print(f"äº¤å‰éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {results_csv_path}")
        
        # æ‰“å°æ€»è¿è¡Œæ—¶é—´
        elapsed_time = time.time() - start_time
        hours, remainder = divmod(elapsed_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        print(f"\näº¤å‰éªŒè¯æ€»æ—¶é—´: {int(hours)}å°æ—¶ {int(minutes)}åˆ†é’Ÿ {seconds:.2f}ç§’")
        
    else:
        # å¸¸è§„è®­ç»ƒæ¨¡å¼ï¼ˆä¸ä½¿ç”¨äº¤å‰éªŒè¯ï¼‰
        print("\nä½¿ç”¨å¸¸è§„è®­ç»ƒæ¨¡å¼ï¼ˆ80%è®­ç»ƒ/20%éªŒè¯ï¼‰")
        
        # åˆ†å‰²æ•°æ®é›†
        val_size = int(0.2 * len(full_dataset))
        train_size = len(full_dataset) - val_size
        
        generator = torch.Generator().manual_seed(args.seed)
        train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)
        
        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)
        val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)
        
        # åˆ›å»ºæ¨¡å‹
        model = CTModel(num_classes=2).to(device)
        
        # åˆ›å»ºæŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        criterion = FocalLoss(alpha=0.25, gamma=2.0)
        optimizer = optim.Lookahead(optim.RAdam(model.parameters(), lr=args.lr))
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)
        
        print(f"\n{'='*20} å¼€å§‹å¸¸è§„è®­ç»ƒ {'='*20}")
        start_time = time.time()
        
        # è®­ç»ƒæ¨¡å‹
        best_f1 = 0.0
        save_path = os.path.join(args.save_dir, 'res2gcsa_best.pth')
        
        progress_bar = tqdm(range(args.epochs), desc="è®­ç»ƒè¿›åº¦", unit="epoch")
        for epoch in progress_bar:
            train_loss, acc, prec, rec, f1 = train(model, train_loader, val_loader, criterion, optimizer, scheduler, device)
            
            # åŠ¨æ€æ›´æ–°è¿›åº¦æ¡æè¿°
            progress_bar.set_description(
                f"Epoch {epoch+1}/{args.epochs} | Loss: {train_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f}"
            )
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if f1 > best_f1:
                best_f1 = f1
                torch.save(model.state_dict(), save_path)
                print(f"  ğŸ‰ æ–°çš„æœ€ä½³F1: {best_f1:.4f}, å·²ä¿å­˜åˆ° {save_path}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_save_path = os.path.join(args.save_dir, 'res2gcsa_final.pth')
        torch.save(model.state_dict(), final_save_path)
        print(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {final_save_path}")
        
        # æ‰“å°æ€»è¿è¡Œæ—¶é—´
        elapsed_time = time.time() - start_time
        hours, remainder = divmod(elapsed_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        print(f"\nè®­ç»ƒæ€»æ—¶é—´: {int(hours)}å°æ—¶ {int(minutes)}åˆ†é’Ÿ {seconds:.2f}ç§’")