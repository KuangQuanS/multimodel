{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b7f11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder for Frag...\n",
      "[Frag] Epoch 1/1000  Train Loss: 0.2729  Val Loss: 0.1300\n",
      "[Frag] Epoch 20/1000  Train Loss: 0.0823  Val Loss: 0.0183\n",
      "[Frag] Epoch 40/1000  Train Loss: 0.0659  Val Loss: 0.0224\n",
      "[Frag] Epoch 60/1000  Train Loss: 0.0592  Val Loss: 0.0250\n",
      "[Frag] Epoch 80/1000  Train Loss: 0.0597  Val Loss: 0.0299\n",
      "[Frag] Epoch 100/1000  Train Loss: 0.0478  Val Loss: 0.0454\n",
      "[Frag] Epoch 120/1000  Train Loss: 0.0428  Val Loss: 0.0166\n",
      "[Frag] Early stopping at epoch 124 (patience=50)\n",
      "[Frag] Best @ epoch 74, Val Loss=0.0118\n",
      "[Frag] Saved best encoder to ./cancer_and_normal_pretrained/Frag_encoder_best.pth\n",
      "[Frag] Saved best full model to ./cancer_and_normal_pretrained/Frag_full_model_best.pth\n",
      "[Frag] Loss curves saved to ./cancer_and_normal_pretrained/Frag_256_epoch124_loss_curve.png\n",
      "Training Autoencoder for CNV...\n",
      "[CNV] Epoch 1/1000  Train Loss: 1.4922  Val Loss: 1.2482\n",
      "[CNV] Epoch 20/1000  Train Loss: 0.3112  Val Loss: 0.0904\n",
      "[CNV] Epoch 40/1000  Train Loss: 0.2635  Val Loss: 0.0624\n",
      "[CNV] Epoch 60/1000  Train Loss: 0.2010  Val Loss: 0.0613\n",
      "[CNV] Epoch 80/1000  Train Loss: 0.2476  Val Loss: 0.0580\n",
      "[CNV] Epoch 100/1000  Train Loss: 0.2488  Val Loss: 0.0972\n",
      "[CNV] Epoch 120/1000  Train Loss: 0.2584  Val Loss: 0.0224\n",
      "[CNV] Epoch 140/1000  Train Loss: 0.2283  Val Loss: 0.0531\n",
      "[CNV] Epoch 160/1000  Train Loss: 0.2064  Val Loss: 0.0366\n",
      "[CNV] Epoch 180/1000  Train Loss: 0.2887  Val Loss: 0.0521\n",
      "[CNV] Early stopping at epoch 185 (patience=50)\n",
      "[CNV] Best @ epoch 135, Val Loss=0.0210\n",
      "[CNV] Saved best encoder to ./cancer_and_normal_pretrained/CNV_encoder_best.pth\n",
      "[CNV] Saved best full model to ./cancer_and_normal_pretrained/CNV_full_model_best.pth\n",
      "[CNV] Loss curves saved to ./cancer_and_normal_pretrained/CNV_256_epoch185_loss_curve.png\n",
      "Training Autoencoder for PFE...\n",
      "[PFE] Epoch 1/1000  Train Loss: 0.2785  Val Loss: 0.2016\n",
      "[PFE] Epoch 20/1000  Train Loss: 0.0417  Val Loss: 0.0559\n",
      "[PFE] Epoch 40/1000  Train Loss: 0.0296  Val Loss: 0.0685\n",
      "[PFE] Epoch 60/1000  Train Loss: 0.0262  Val Loss: 0.0140\n",
      "[PFE] Epoch 80/1000  Train Loss: 0.0213  Val Loss: 0.0077\n",
      "[PFE] Epoch 100/1000  Train Loss: 0.0195  Val Loss: 0.0283\n",
      "[PFE] Epoch 120/1000  Train Loss: 0.0165  Val Loss: 0.0204\n",
      "[PFE] Early stopping at epoch 126 (patience=50)\n",
      "[PFE] Best @ epoch 76, Val Loss=0.0041\n",
      "[PFE] Saved best encoder to ./cancer_and_normal_pretrained/PFE_encoder_best.pth\n",
      "[PFE] Saved best full model to ./cancer_and_normal_pretrained/PFE_full_model_best.pth\n",
      "[PFE] Loss curves saved to ./cancer_and_normal_pretrained/PFE_256_epoch126_loss_curve.png\n",
      "Training Autoencoder for NDR...\n",
      "[NDR] Epoch 1/1000  Train Loss: 1.7015  Val Loss: 1.1047\n",
      "[NDR] Epoch 20/1000  Train Loss: 0.9398  Val Loss: 0.6201\n",
      "[NDR] Epoch 40/1000  Train Loss: 0.7938  Val Loss: 0.5425\n",
      "[NDR] Epoch 60/1000  Train Loss: 0.7053  Val Loss: 0.5167\n",
      "[NDR] Epoch 80/1000  Train Loss: 0.6369  Val Loss: 0.4787\n",
      "[NDR] Epoch 100/1000  Train Loss: 0.5908  Val Loss: 0.4917\n",
      "[NDR] Epoch 120/1000  Train Loss: 0.5594  Val Loss: 0.4623\n",
      "[NDR] Epoch 140/1000  Train Loss: 0.5312  Val Loss: 0.4454\n",
      "[NDR] Epoch 160/1000  Train Loss: 0.4947  Val Loss: 0.4269\n",
      "[NDR] Epoch 180/1000  Train Loss: 0.4587  Val Loss: 0.4163\n",
      "[NDR] Epoch 200/1000  Train Loss: 0.4253  Val Loss: 0.4048\n",
      "[NDR] Epoch 220/1000  Train Loss: 0.4257  Val Loss: 0.4026\n",
      "[NDR] Epoch 240/1000  Train Loss: 0.3864  Val Loss: 0.3919\n",
      "[NDR] Epoch 260/1000  Train Loss: 0.3652  Val Loss: 0.3804\n",
      "[NDR] Epoch 280/1000  Train Loss: 0.3556  Val Loss: 0.3755\n",
      "[NDR] Epoch 300/1000  Train Loss: 0.3473  Val Loss: 0.3647\n",
      "[NDR] Epoch 320/1000  Train Loss: 0.3267  Val Loss: 0.3478\n",
      "[NDR] Epoch 340/1000  Train Loss: 0.3095  Val Loss: 0.3536\n",
      "[NDR] Epoch 360/1000  Train Loss: 0.3077  Val Loss: 0.3529\n",
      "[NDR] Epoch 380/1000  Train Loss: 0.2837  Val Loss: 0.3455\n",
      "[NDR] Epoch 400/1000  Train Loss: 0.2701  Val Loss: 0.3342\n",
      "[NDR] Epoch 420/1000  Train Loss: 0.2901  Val Loss: 0.3462\n",
      "[NDR] Epoch 440/1000  Train Loss: 0.2665  Val Loss: 0.3316\n",
      "[NDR] Epoch 460/1000  Train Loss: 0.2581  Val Loss: 0.3351\n",
      "[NDR] Epoch 480/1000  Train Loss: 0.2517  Val Loss: 0.3394\n",
      "[NDR] Epoch 500/1000  Train Loss: 0.2555  Val Loss: 0.3329\n",
      "[NDR] Epoch 520/1000  Train Loss: 0.2488  Val Loss: 0.3444\n",
      "[NDR] Epoch 540/1000  Train Loss: 0.2479  Val Loss: 0.3424\n",
      "[NDR] Epoch 560/1000  Train Loss: 0.2450  Val Loss: 0.3445\n",
      "[NDR] Epoch 580/1000  Train Loss: 0.2466  Val Loss: 0.3401\n",
      "[NDR] Epoch 600/1000  Train Loss: 0.2219  Val Loss: 0.3295\n",
      "[NDR] Epoch 620/1000  Train Loss: 0.2395  Val Loss: 0.3185\n",
      "[NDR] Epoch 640/1000  Train Loss: 0.2292  Val Loss: 0.3369\n",
      "[NDR] Epoch 660/1000  Train Loss: 0.2186  Val Loss: 0.3225\n",
      "[NDR] Epoch 680/1000  Train Loss: 0.2107  Val Loss: 0.3132\n",
      "[NDR] Epoch 700/1000  Train Loss: 0.2074  Val Loss: 0.3145\n",
      "[NDR] Epoch 720/1000  Train Loss: 0.2111  Val Loss: 0.3312\n",
      "[NDR] Early stopping at epoch 733 (patience=50)\n",
      "[NDR] Best @ epoch 683, Val Loss=0.3071\n",
      "[NDR] Saved best encoder to ./cancer_and_normal_pretrained/NDR_encoder_best.pth\n",
      "[NDR] Saved best full model to ./cancer_and_normal_pretrained/NDR_full_model_best.pth\n",
      "[NDR] Loss curves saved to ./cancer_and_normal_pretrained/NDR_256_epoch733_loss_curve.png\n",
      "Training Autoencoder for NDR2K...\n",
      "[NDR2K] Epoch 1/1000  Train Loss: 1.1481  Val Loss: 0.9225\n",
      "[NDR2K] Epoch 20/1000  Train Loss: 0.4032  Val Loss: 0.4381\n",
      "[NDR2K] Epoch 40/1000  Train Loss: 0.3438  Val Loss: 0.3957\n",
      "[NDR2K] Epoch 60/1000  Train Loss: 0.3168  Val Loss: 0.3716\n",
      "[NDR2K] Epoch 80/1000  Train Loss: 0.2947  Val Loss: 0.3630\n",
      "[NDR2K] Epoch 100/1000  Train Loss: 0.2780  Val Loss: 0.3708\n",
      "[NDR2K] Epoch 120/1000  Train Loss: 0.2733  Val Loss: 0.3651\n",
      "[NDR2K] Epoch 140/1000  Train Loss: 0.2536  Val Loss: 0.3426\n",
      "[NDR2K] Epoch 160/1000  Train Loss: 0.2312  Val Loss: 0.3361\n",
      "[NDR2K] Epoch 180/1000  Train Loss: 0.2219  Val Loss: 0.3215\n",
      "[NDR2K] Epoch 200/1000  Train Loss: 0.2087  Val Loss: 0.3093\n",
      "[NDR2K] Epoch 220/1000  Train Loss: 0.1928  Val Loss: 0.3098\n",
      "[NDR2K] Epoch 240/1000  Train Loss: 0.1812  Val Loss: 0.3093\n",
      "[NDR2K] Epoch 260/1000  Train Loss: 0.1703  Val Loss: 0.2781\n",
      "[NDR2K] Epoch 280/1000  Train Loss: 0.1642  Val Loss: 0.2763\n",
      "[NDR2K] Epoch 300/1000  Train Loss: 0.1594  Val Loss: 0.2625\n",
      "[NDR2K] Epoch 320/1000  Train Loss: 0.1494  Val Loss: 0.2586\n",
      "[NDR2K] Epoch 340/1000  Train Loss: 0.1370  Val Loss: 0.2499\n",
      "[NDR2K] Epoch 360/1000  Train Loss: 0.1348  Val Loss: 0.2673\n",
      "[NDR2K] Epoch 380/1000  Train Loss: 0.1306  Val Loss: 0.2687\n",
      "[NDR2K] Epoch 400/1000  Train Loss: 0.1249  Val Loss: 0.2294\n",
      "[NDR2K] Epoch 420/1000  Train Loss: 0.1170  Val Loss: 0.2356\n",
      "[NDR2K] Epoch 440/1000  Train Loss: 0.1140  Val Loss: 0.2292\n",
      "[NDR2K] Epoch 460/1000  Train Loss: 0.1141  Val Loss: 0.2314\n",
      "[NDR2K] Epoch 480/1000  Train Loss: 0.1048  Val Loss: 0.2207\n",
      "[NDR2K] Epoch 500/1000  Train Loss: 0.1055  Val Loss: 0.2325\n",
      "[NDR2K] Epoch 520/1000  Train Loss: 0.1069  Val Loss: 0.2245\n",
      "[NDR2K] Epoch 540/1000  Train Loss: 0.0946  Val Loss: 0.2173\n",
      "[NDR2K] Epoch 560/1000  Train Loss: 0.0968  Val Loss: 0.2152\n",
      "[NDR2K] Early stopping at epoch 578 (patience=50)\n",
      "[NDR2K] Best @ epoch 528, Val Loss=0.2083\n",
      "[NDR2K] Saved best encoder to ./cancer_and_normal_pretrained/NDR2K_encoder_best.pth\n",
      "[NDR2K] Saved best full model to ./cancer_and_normal_pretrained/NDR2K_full_model_best.pth\n",
      "[NDR2K] Loss curves saved to ./cancer_and_normal_pretrained/NDR2K_256_epoch578_loss_curve.png\n"
     ]
    }
   ],
   "source": [
    "%run encoder_pretrain.py \\\n",
    "    --modalities Frag CNV PFE NDR NDR2K \\\n",
    "    --data_file /home/maweicheng/database/cfDNA/cancer_and_normal/train.npz \\\n",
    "    --save_dir ./cancer_and_normal_pretrained \\\n",
    "    --epochs 1000 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3235509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder for Frag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Frag] Epoch 1/1000  Train Loss: 0.2338  Val Loss: 0.0899\n",
      "[Frag] Epoch 20/1000  Train Loss: 0.0876  Val Loss: 0.0561\n",
      "[Frag] Epoch 40/1000  Train Loss: 0.0500  Val Loss: 0.0193\n",
      "[Frag] Epoch 60/1000  Train Loss: 0.0410  Val Loss: 0.0103\n",
      "[Frag] Epoch 80/1000  Train Loss: 0.0356  Val Loss: 0.0067\n",
      "[Frag] Epoch 100/1000  Train Loss: 0.0318  Val Loss: 0.0055\n",
      "[Frag] Epoch 120/1000  Train Loss: 0.0291  Val Loss: 0.0050\n",
      "[Frag] Epoch 140/1000  Train Loss: 0.0252  Val Loss: 0.0042\n",
      "[Frag] Epoch 160/1000  Train Loss: 0.0244  Val Loss: 0.0061\n",
      "[Frag] Epoch 180/1000  Train Loss: 0.0214  Val Loss: 0.0041\n",
      "[Frag] Epoch 200/1000  Train Loss: 0.0188  Val Loss: 0.0068\n",
      "[Frag] Epoch 220/1000  Train Loss: 0.0164  Val Loss: 0.0049\n",
      "[Frag] Epoch 240/1000  Train Loss: 0.0158  Val Loss: 0.0031\n",
      "[Frag] Epoch 260/1000  Train Loss: 0.0139  Val Loss: 0.0033\n",
      "[Frag] Epoch 280/1000  Train Loss: 0.0144  Val Loss: 0.0058\n",
      "[Frag] Epoch 300/1000  Train Loss: 0.0144  Val Loss: 0.0032\n",
      "[Frag] Epoch 320/1000  Train Loss: 0.0114  Val Loss: 0.0070\n",
      "[Frag] Epoch 340/1000  Train Loss: 0.0107  Val Loss: 0.0027\n",
      "[Frag] Epoch 360/1000  Train Loss: 0.0108  Val Loss: 0.0058\n",
      "[Frag] Epoch 380/1000  Train Loss: 0.0109  Val Loss: 0.0069\n",
      "[Frag] Epoch 400/1000  Train Loss: 0.0098  Val Loss: 0.0029\n",
      "[Frag] Epoch 420/1000  Train Loss: 0.0108  Val Loss: 0.0074\n",
      "[Frag] Early stopping at epoch 427 (patience=50)\n",
      "[Frag] Best @ epoch 377, Val Loss=0.0021\n",
      "[Frag] Saved best encoder to ./cancer_and_benign_pretrained/Frag_encoder_best.pth\n",
      "[Frag] Saved best full model to ./cancer_and_benign_pretrained/Frag_full_model_best.pth\n",
      "[Frag] Loss curves saved to ./cancer_and_benign_pretrained/Frag_256_epoch427_loss_curve.png\n",
      "Training Autoencoder for CNV...\n",
      "[CNV] Epoch 1/1000  Train Loss: 3.0274  Val Loss: 2.2910\n",
      "[CNV] Epoch 20/1000  Train Loss: 0.2458  Val Loss: 0.2055\n",
      "[CNV] Epoch 40/1000  Train Loss: 0.1950  Val Loss: 0.1533\n",
      "[CNV] Epoch 60/1000  Train Loss: 0.1618  Val Loss: 0.1988\n",
      "[CNV] Epoch 80/1000  Train Loss: 0.1555  Val Loss: 0.1302\n",
      "[CNV] Epoch 100/1000  Train Loss: 0.1614  Val Loss: 0.1699\n",
      "[CNV] Epoch 120/1000  Train Loss: 0.1529  Val Loss: 0.1412\n",
      "[CNV] Epoch 140/1000  Train Loss: 0.1456  Val Loss: 0.1677\n",
      "[CNV] Epoch 160/1000  Train Loss: 0.1234  Val Loss: 0.0999\n",
      "[CNV] Epoch 180/1000  Train Loss: 0.1318  Val Loss: 0.1268\n",
      "[CNV] Epoch 200/1000  Train Loss: 0.1297  Val Loss: 0.0951\n",
      "[CNV] Epoch 220/1000  Train Loss: 0.1000  Val Loss: 0.1133\n",
      "[CNV] Epoch 240/1000  Train Loss: 0.1358  Val Loss: 0.0739\n",
      "[CNV] Epoch 260/1000  Train Loss: 0.1089  Val Loss: 0.1133\n",
      "[CNV] Epoch 280/1000  Train Loss: 0.1649  Val Loss: 0.0845\n",
      "[CNV] Early stopping at epoch 281 (patience=50)\n",
      "[CNV] Best @ epoch 231, Val Loss=0.0558\n",
      "[CNV] Saved best encoder to ./cancer_and_benign_pretrained/CNV_encoder_best.pth\n",
      "[CNV] Saved best full model to ./cancer_and_benign_pretrained/CNV_full_model_best.pth\n",
      "[CNV] Loss curves saved to ./cancer_and_benign_pretrained/CNV_256_epoch281_loss_curve.png\n",
      "Training Autoencoder for PFE...\n",
      "[PFE] Epoch 1/1000  Train Loss: 0.3522  Val Loss: 0.3102\n",
      "[PFE] Epoch 20/1000  Train Loss: 0.1009  Val Loss: 0.0855\n",
      "[PFE] Epoch 40/1000  Train Loss: 0.0545  Val Loss: 0.0864\n",
      "[PFE] Epoch 60/1000  Train Loss: 0.0391  Val Loss: 0.0731\n",
      "[PFE] Epoch 80/1000  Train Loss: 0.0369  Val Loss: 0.1344\n",
      "[PFE] Early stopping at epoch 82 (patience=50)\n",
      "[PFE] Best @ epoch 32, Val Loss=0.0396\n",
      "[PFE] Saved best encoder to ./cancer_and_benign_pretrained/PFE_encoder_best.pth\n",
      "[PFE] Saved best full model to ./cancer_and_benign_pretrained/PFE_full_model_best.pth\n",
      "[PFE] Loss curves saved to ./cancer_and_benign_pretrained/PFE_256_epoch82_loss_curve.png\n",
      "Training Autoencoder for NDR...\n",
      "[NDR] Epoch 1/1000  Train Loss: 1.5041  Val Loss: 1.3019\n",
      "[NDR] Epoch 20/1000  Train Loss: 0.7549  Val Loss: 0.7036\n",
      "[NDR] Epoch 40/1000  Train Loss: 0.6768  Val Loss: 0.6510\n",
      "[NDR] Epoch 60/1000  Train Loss: 0.6101  Val Loss: 0.6148\n",
      "[NDR] Epoch 80/1000  Train Loss: 0.5818  Val Loss: 0.5908\n",
      "[NDR] Epoch 100/1000  Train Loss: 0.5258  Val Loss: 0.5530\n",
      "[NDR] Epoch 120/1000  Train Loss: 0.4854  Val Loss: 0.5554\n",
      "[NDR] Epoch 140/1000  Train Loss: 0.4585  Val Loss: 0.5145\n",
      "[NDR] Epoch 160/1000  Train Loss: 0.4239  Val Loss: 0.5217\n",
      "[NDR] Epoch 180/1000  Train Loss: 0.4189  Val Loss: 0.5325\n",
      "[NDR] Epoch 200/1000  Train Loss: 0.3845  Val Loss: 0.5139\n",
      "[NDR] Epoch 220/1000  Train Loss: 0.3656  Val Loss: 0.5230\n",
      "[NDR] Epoch 240/1000  Train Loss: 0.3340  Val Loss: 0.5325\n",
      "[NDR] Early stopping at epoch 246 (patience=50)\n",
      "[NDR] Best @ epoch 196, Val Loss=0.4902\n",
      "[NDR] Saved best encoder to ./cancer_and_benign_pretrained/NDR_encoder_best.pth\n",
      "[NDR] Saved best full model to ./cancer_and_benign_pretrained/NDR_full_model_best.pth\n",
      "[NDR] Loss curves saved to ./cancer_and_benign_pretrained/NDR_256_epoch246_loss_curve.png\n",
      "Training Autoencoder for NDR2K...\n",
      "[NDR2K] Epoch 1/1000  Train Loss: 1.1744  Val Loss: 1.2138\n",
      "[NDR2K] Epoch 20/1000  Train Loss: 0.3939  Val Loss: 0.5721\n",
      "[NDR2K] Epoch 40/1000  Train Loss: 0.3349  Val Loss: 0.5241\n",
      "[NDR2K] Epoch 60/1000  Train Loss: 0.2923  Val Loss: 0.4938\n",
      "[NDR2K] Epoch 80/1000  Train Loss: 0.2722  Val Loss: 0.4526\n",
      "[NDR2K] Epoch 100/1000  Train Loss: 0.2634  Val Loss: 0.4417\n",
      "[NDR2K] Epoch 120/1000  Train Loss: 0.2466  Val Loss: 0.4245\n",
      "[NDR2K] Epoch 140/1000  Train Loss: 0.2424  Val Loss: 0.4222\n",
      "[NDR2K] Epoch 160/1000  Train Loss: 0.2328  Val Loss: 0.4060\n",
      "[NDR2K] Epoch 180/1000  Train Loss: 0.2251  Val Loss: 0.4029\n",
      "[NDR2K] Epoch 200/1000  Train Loss: 0.2165  Val Loss: 0.3988\n",
      "[NDR2K] Epoch 220/1000  Train Loss: 0.2076  Val Loss: 0.3962\n",
      "[NDR2K] Epoch 240/1000  Train Loss: 0.2029  Val Loss: 0.3961\n",
      "[NDR2K] Epoch 260/1000  Train Loss: 0.1926  Val Loss: 0.3894\n",
      "[NDR2K] Epoch 280/1000  Train Loss: 0.1951  Val Loss: 0.3846\n",
      "[NDR2K] Epoch 300/1000  Train Loss: 0.1834  Val Loss: 0.3873\n",
      "[NDR2K] Epoch 320/1000  Train Loss: 0.1793  Val Loss: 0.3844\n",
      "[NDR2K] Epoch 340/1000  Train Loss: 0.1657  Val Loss: 0.3958\n",
      "[NDR2K] Epoch 360/1000  Train Loss: 0.1587  Val Loss: 0.4035\n",
      "[NDR2K] Epoch 380/1000  Train Loss: 0.1558  Val Loss: 0.3796\n",
      "[NDR2K] Epoch 400/1000  Train Loss: 0.1505  Val Loss: 0.3925\n",
      "[NDR2K] Early stopping at epoch 418 (patience=50)\n",
      "[NDR2K] Best @ epoch 368, Val Loss=0.3705\n",
      "[NDR2K] Saved best encoder to ./cancer_and_benign_pretrained/NDR2K_encoder_best.pth\n",
      "[NDR2K] Saved best full model to ./cancer_and_benign_pretrained/NDR2K_full_model_best.pth\n",
      "[NDR2K] Loss curves saved to ./cancer_and_benign_pretrained/NDR2K_256_epoch418_loss_curve.png\n"
     ]
    }
   ],
   "source": [
    "%run encoder_pretrain.py \\\n",
    "    --modalities Frag CNV PFE NDR NDR2K \\\n",
    "    --data_file /home/maweicheng/database/cfDNA/cancer_and_benign/train.npz \\\n",
    "    --save_dir ./cancer_and_benign_pretrained \\\n",
    "    --epochs 1000 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf18723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder for Frag...\n",
      "[Frag] Epoch 1/1000  Train Loss: 0.2519  Val Loss: 0.0752\n",
      "[Frag] Epoch 20/1000  Train Loss: 0.1304  Val Loss: 0.0784\n",
      "[Frag] Epoch 40/1000  Train Loss: 0.1063  Val Loss: 0.0599\n",
      "[Frag] Epoch 60/1000  Train Loss: 0.0817  Val Loss: 0.0457\n",
      "[Frag] Epoch 80/1000  Train Loss: 0.0684  Val Loss: 0.0281\n",
      "[Frag] Epoch 100/1000  Train Loss: 0.0553  Val Loss: 0.0206\n",
      "[Frag] Epoch 120/1000  Train Loss: 0.0490  Val Loss: 0.0146\n",
      "[Frag] Epoch 140/1000  Train Loss: 0.0445  Val Loss: 0.0106\n",
      "[Frag] Epoch 160/1000  Train Loss: 0.0412  Val Loss: 0.0084\n",
      "[Frag] Epoch 180/1000  Train Loss: 0.0410  Val Loss: 0.0069\n",
      "[Frag] Epoch 200/1000  Train Loss: 0.0398  Val Loss: 0.0053\n",
      "[Frag] Epoch 220/1000  Train Loss: 0.0395  Val Loss: 0.0052\n",
      "[Frag] Epoch 240/1000  Train Loss: 0.0360  Val Loss: 0.0059\n",
      "[Frag] Epoch 260/1000  Train Loss: 0.0368  Val Loss: 0.0059\n",
      "[Frag] Epoch 280/1000  Train Loss: 0.0333  Val Loss: 0.0045\n",
      "[Frag] Epoch 300/1000  Train Loss: 0.0287  Val Loss: 0.0040\n",
      "[Frag] Epoch 320/1000  Train Loss: 0.0271  Val Loss: 0.0035\n",
      "[Frag] Epoch 340/1000  Train Loss: 0.0324  Val Loss: 0.0024\n",
      "[Frag] Epoch 360/1000  Train Loss: 0.0302  Val Loss: 0.0026\n",
      "[Frag] Epoch 380/1000  Train Loss: 0.0284  Val Loss: 0.0035\n",
      "[Frag] Early stopping at epoch 390 (patience=50)\n",
      "[Frag] Best @ epoch 340, Val Loss=0.0024\n",
      "[Frag] Saved best encoder to ./subtype_pretrained/Frag_encoder_best.pth\n",
      "[Frag] Saved best full model to ./subtype_pretrained/Frag_full_model_best.pth\n",
      "[Frag] Loss curves saved to ./subtype_pretrained/Frag_256_epoch390_loss_curve.png\n",
      "Training Autoencoder for CNV...\n",
      "[CNV] Epoch 1/1000  Train Loss: 2.9685  Val Loss: 2.1406\n",
      "[CNV] Epoch 20/1000  Train Loss: 0.6711  Val Loss: 0.5903\n",
      "[CNV] Epoch 40/1000  Train Loss: 0.2549  Val Loss: 0.1570\n",
      "[CNV] Epoch 60/1000  Train Loss: 0.2453  Val Loss: 0.1256\n",
      "[CNV] Epoch 80/1000  Train Loss: 0.1706  Val Loss: 0.1165\n",
      "[CNV] Epoch 100/1000  Train Loss: 0.1845  Val Loss: 0.1131\n",
      "[CNV] Epoch 120/1000  Train Loss: 0.1704  Val Loss: 0.1039\n",
      "[CNV] Epoch 140/1000  Train Loss: 0.1461  Val Loss: 0.1023\n",
      "[CNV] Epoch 160/1000  Train Loss: 0.2873  Val Loss: 0.1376\n",
      "[CNV] Early stopping at epoch 171 (patience=50)\n",
      "[CNV] Best @ epoch 121, Val Loss=0.0851\n",
      "[CNV] Saved best encoder to ./subtype_pretrained/CNV_encoder_best.pth\n",
      "[CNV] Saved best full model to ./subtype_pretrained/CNV_full_model_best.pth\n",
      "[CNV] Loss curves saved to ./subtype_pretrained/CNV_256_epoch171_loss_curve.png\n",
      "Training Autoencoder for PFE...\n",
      "[PFE] Epoch 1/1000  Train Loss: 0.3694  Val Loss: 0.2622\n",
      "[PFE] Epoch 20/1000  Train Loss: 0.1383  Val Loss: 0.1457\n",
      "[PFE] Epoch 40/1000  Train Loss: 0.1085  Val Loss: 0.1312\n",
      "[PFE] Epoch 60/1000  Train Loss: 0.0827  Val Loss: 0.1148\n",
      "[PFE] Epoch 80/1000  Train Loss: 0.0614  Val Loss: 0.0396\n",
      "[PFE] Epoch 100/1000  Train Loss: 0.0559  Val Loss: 0.0313\n",
      "[PFE] Epoch 120/1000  Train Loss: 0.0488  Val Loss: 0.0282\n",
      "[PFE] Epoch 140/1000  Train Loss: 0.0438  Val Loss: 0.0298\n",
      "[PFE] Epoch 160/1000  Train Loss: 0.0403  Val Loss: 0.0627\n",
      "[PFE] Epoch 180/1000  Train Loss: 0.0479  Val Loss: 0.0883\n",
      "[PFE] Early stopping at epoch 196 (patience=50)\n",
      "[PFE] Best @ epoch 146, Val Loss=0.0217\n",
      "[PFE] Saved best encoder to ./subtype_pretrained/PFE_encoder_best.pth\n",
      "[PFE] Saved best full model to ./subtype_pretrained/PFE_full_model_best.pth\n",
      "[PFE] Loss curves saved to ./subtype_pretrained/PFE_256_epoch196_loss_curve.png\n",
      "Training Autoencoder for NDR...\n",
      "[NDR] Epoch 1/1000  Train Loss: 1.7178  Val Loss: 1.0737\n",
      "[NDR] Epoch 20/1000  Train Loss: 1.0275  Val Loss: 0.5979\n",
      "[NDR] Epoch 40/1000  Train Loss: 0.8647  Val Loss: 0.5238\n",
      "[NDR] Epoch 60/1000  Train Loss: 0.9469  Val Loss: 0.4999\n",
      "[NDR] Epoch 80/1000  Train Loss: 0.8876  Val Loss: 0.5005\n",
      "[NDR] Epoch 100/1000  Train Loss: 0.7844  Val Loss: 0.4799\n",
      "[NDR] Epoch 120/1000  Train Loss: 0.8045  Val Loss: 0.4709\n",
      "[NDR] Epoch 140/1000  Train Loss: 0.7258  Val Loss: 0.4602\n",
      "[NDR] Epoch 160/1000  Train Loss: 0.8176  Val Loss: 0.4684\n",
      "[NDR] Epoch 180/1000  Train Loss: 0.7177  Val Loss: 0.4472\n",
      "[NDR] Epoch 200/1000  Train Loss: 0.5974  Val Loss: 0.4463\n",
      "[NDR] Epoch 220/1000  Train Loss: 0.5894  Val Loss: 0.4339\n",
      "[NDR] Epoch 240/1000  Train Loss: 0.5472  Val Loss: 0.4194\n",
      "[NDR] Epoch 260/1000  Train Loss: 0.8161  Val Loss: 0.4316\n",
      "[NDR] Epoch 280/1000  Train Loss: 0.5758  Val Loss: 0.4378\n",
      "[NDR] Epoch 300/1000  Train Loss: 0.6860  Val Loss: 0.4099\n",
      "[NDR] Epoch 320/1000  Train Loss: 0.5404  Val Loss: 0.4036\n",
      "[NDR] Epoch 340/1000  Train Loss: 0.4813  Val Loss: 0.3947\n",
      "[NDR] Epoch 360/1000  Train Loss: 0.4757  Val Loss: 0.3924\n",
      "[NDR] Epoch 380/1000  Train Loss: 0.4494  Val Loss: 0.3881\n",
      "[NDR] Epoch 400/1000  Train Loss: 0.4763  Val Loss: 0.3818\n",
      "[NDR] Epoch 420/1000  Train Loss: 0.4414  Val Loss: 0.3935\n",
      "[NDR] Epoch 440/1000  Train Loss: 0.4105  Val Loss: 0.3855\n",
      "[NDR] Epoch 460/1000  Train Loss: 0.4002  Val Loss: 0.3776\n",
      "[NDR] Epoch 480/1000  Train Loss: 0.3967  Val Loss: 0.3757\n",
      "[NDR] Epoch 500/1000  Train Loss: 0.3570  Val Loss: 0.3806\n",
      "[NDR] Epoch 520/1000  Train Loss: 0.5412  Val Loss: 0.3752\n",
      "[NDR] Early stopping at epoch 531 (patience=50)\n",
      "[NDR] Best @ epoch 481, Val Loss=0.3680\n",
      "[NDR] Saved best encoder to ./subtype_pretrained/NDR_encoder_best.pth\n",
      "[NDR] Saved best full model to ./subtype_pretrained/NDR_full_model_best.pth\n",
      "[NDR] Loss curves saved to ./subtype_pretrained/NDR_256_epoch531_loss_curve.png\n",
      "Training Autoencoder for NDR2K...\n",
      "[NDR2K] Epoch 1/1000  Train Loss: 1.4088  Val Loss: 0.8856\n",
      "[NDR2K] Epoch 20/1000  Train Loss: 0.6971  Val Loss: 0.3438\n",
      "[NDR2K] Epoch 40/1000  Train Loss: 0.5444  Val Loss: 0.2804\n",
      "[NDR2K] Epoch 60/1000  Train Loss: 0.6212  Val Loss: 0.2806\n",
      "[NDR2K] Epoch 80/1000  Train Loss: 0.6797  Val Loss: 0.2492\n",
      "[NDR2K] Epoch 100/1000  Train Loss: 0.4297  Val Loss: 0.2322\n",
      "[NDR2K] Epoch 120/1000  Train Loss: 0.4220  Val Loss: 0.2203\n",
      "[NDR2K] Epoch 140/1000  Train Loss: 0.4528  Val Loss: 0.2219\n",
      "[NDR2K] Epoch 160/1000  Train Loss: 0.4947  Val Loss: 0.2089\n",
      "[NDR2K] Epoch 180/1000  Train Loss: 0.4180  Val Loss: 0.1990\n",
      "[NDR2K] Epoch 200/1000  Train Loss: 0.4703  Val Loss: 0.1904\n",
      "[NDR2K] Epoch 220/1000  Train Loss: 0.5204  Val Loss: 0.1899\n",
      "[NDR2K] Epoch 240/1000  Train Loss: 0.3816  Val Loss: 0.1801\n",
      "[NDR2K] Epoch 260/1000  Train Loss: 0.4868  Val Loss: 0.1779\n",
      "[NDR2K] Epoch 280/1000  Train Loss: 0.4235  Val Loss: 0.1760\n",
      "[NDR2K] Epoch 300/1000  Train Loss: 0.3144  Val Loss: 0.1775\n",
      "[NDR2K] Epoch 320/1000  Train Loss: 0.3179  Val Loss: 0.1700\n",
      "[NDR2K] Epoch 340/1000  Train Loss: 0.3759  Val Loss: 0.1817\n",
      "[NDR2K] Early stopping at epoch 346 (patience=50)\n",
      "[NDR2K] Best @ epoch 296, Val Loss=0.1650\n",
      "[NDR2K] Saved best encoder to ./subtype_pretrained/NDR2K_encoder_best.pth\n",
      "[NDR2K] Saved best full model to ./subtype_pretrained/NDR2K_full_model_best.pth\n",
      "[NDR2K] Loss curves saved to ./subtype_pretrained/NDR2K_256_epoch346_loss_curve.png\n"
     ]
    }
   ],
   "source": [
    "%run encoder_pretrain.py \\\n",
    "    --modalities Frag CNV PFE NDR NDR2K \\\n",
    "    --data_file /home/maweicheng/database/cfDNA/subtype/train.npz \\\n",
    "    --save_dir ./subtype_pretrained \\\n",
    "    --epochs 1000 \\\n",
    "    --batch_size 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
