{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3235509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder for Frag...\n",
      "[Frag] Epoch 1/1000  Train Loss: 0.2197  Val Loss: 0.0575\n",
      "[Frag] Epoch 20/1000  Train Loss: 0.0495  Val Loss: 0.0482\n",
      "[Frag] Epoch 40/1000  Train Loss: 0.0372  Val Loss: 0.0181\n",
      "[Frag] Epoch 60/1000  Train Loss: 0.0332  Val Loss: 0.0131\n",
      "[Frag] Epoch 80/1000  Train Loss: 0.0264  Val Loss: 0.0080\n",
      "[Frag] Epoch 100/1000  Train Loss: 0.0255  Val Loss: 0.0048\n",
      "[Frag] Epoch 120/1000  Train Loss: 0.0210  Val Loss: 0.0048\n",
      "[Frag] Epoch 140/1000  Train Loss: 0.0241  Val Loss: 0.0060\n",
      "[Frag] Epoch 160/1000  Train Loss: 0.0191  Val Loss: 0.0051\n",
      "[Frag] Epoch 180/1000  Train Loss: 0.0165  Val Loss: 0.0043\n",
      "[Frag] Epoch 200/1000  Train Loss: 0.0187  Val Loss: 0.0058\n",
      "[Frag] Early stopping at epoch 203 (patience=50)\n",
      "[Frag] Best @ epoch 153, Val Loss=0.0034\n",
      "[Frag] Saved best encoder to ./cancer_and_benign_pretrained/Frag_encoder_best.pth\n",
      "[Frag] Saved best full model to ./cancer_and_benign_pretrained/Frag_full_model_best.pth\n",
      "[Frag] Loss curves saved to ./cancer_and_benign_pretrained/Frag_256_epoch203_loss_curve.png\n",
      "Training Autoencoder for CNV...\n",
      "[CNV] Epoch 1/1000  Train Loss: 2.7066  Val Loss: 4.3174\n",
      "[CNV] Epoch 20/1000  Train Loss: 0.3159  Val Loss: 0.4873\n",
      "[CNV] Epoch 40/1000  Train Loss: 0.1666  Val Loss: 0.2576\n",
      "[CNV] Epoch 60/1000  Train Loss: 0.1477  Val Loss: 0.2522\n",
      "[CNV] Epoch 80/1000  Train Loss: 0.1599  Val Loss: 0.1800\n",
      "[CNV] Epoch 100/1000  Train Loss: 0.1386  Val Loss: 0.1514\n",
      "[CNV] Epoch 120/1000  Train Loss: 0.1564  Val Loss: 0.4070\n",
      "[CNV] Epoch 140/1000  Train Loss: 0.1149  Val Loss: 0.1560\n",
      "[CNV] Epoch 160/1000  Train Loss: 0.1190  Val Loss: 0.0940\n",
      "[CNV] Epoch 180/1000  Train Loss: 0.0922  Val Loss: 0.1255\n",
      "[CNV] Epoch 200/1000  Train Loss: 0.1222  Val Loss: 0.3783\n",
      "[CNV] Early stopping at epoch 209 (patience=50)\n",
      "[CNV] Best @ epoch 159, Val Loss=0.0933\n",
      "[CNV] Saved best encoder to ./cancer_and_benign_pretrained/CNV_encoder_best.pth\n",
      "[CNV] Saved best full model to ./cancer_and_benign_pretrained/CNV_full_model_best.pth\n",
      "[CNV] Loss curves saved to ./cancer_and_benign_pretrained/CNV_256_epoch209_loss_curve.png\n",
      "Training Autoencoder for PFE...\n",
      "[PFE] Epoch 1/1000  Train Loss: 0.3547  Val Loss: 0.1804\n",
      "[PFE] Epoch 20/1000  Train Loss: 0.0553  Val Loss: 0.2933\n",
      "[PFE] Epoch 40/1000  Train Loss: 0.0449  Val Loss: 0.0944\n",
      "[PFE] Epoch 60/1000  Train Loss: 0.0344  Val Loss: 0.0506\n",
      "[PFE] Epoch 80/1000  Train Loss: 0.0315  Val Loss: 0.0467\n",
      "[PFE] Epoch 100/1000  Train Loss: 0.0283  Val Loss: 0.0634\n",
      "[PFE] Epoch 120/1000  Train Loss: 0.0319  Val Loss: 0.0310\n",
      "[PFE] Epoch 140/1000  Train Loss: 0.0307  Val Loss: 0.0850\n",
      "[PFE] Epoch 160/1000  Train Loss: 0.0341  Val Loss: 0.0196\n",
      "[PFE] Epoch 180/1000  Train Loss: 0.0245  Val Loss: 0.0302\n",
      "[PFE] Epoch 200/1000  Train Loss: 0.0232  Val Loss: 0.0404\n",
      "[PFE] Early stopping at epoch 220 (patience=50)\n",
      "[PFE] Best @ epoch 170, Val Loss=0.0193\n",
      "[PFE] Saved best encoder to ./cancer_and_benign_pretrained/PFE_encoder_best.pth\n",
      "[PFE] Saved best full model to ./cancer_and_benign_pretrained/PFE_full_model_best.pth\n",
      "[PFE] Loss curves saved to ./cancer_and_benign_pretrained/PFE_256_epoch220_loss_curve.png\n",
      "Training Autoencoder for NDR...\n",
      "[NDR] Epoch 1/1000  Train Loss: 1.4736  Val Loss: 1.2460\n",
      "[NDR] Epoch 20/1000  Train Loss: 0.7011  Val Loss: 0.8362\n",
      "[NDR] Epoch 40/1000  Train Loss: 0.6046  Val Loss: 0.7652\n",
      "[NDR] Epoch 60/1000  Train Loss: 0.5437  Val Loss: 0.6963\n",
      "[NDR] Epoch 80/1000  Train Loss: 0.5040  Val Loss: 0.6484\n",
      "[NDR] Epoch 100/1000  Train Loss: 0.4675  Val Loss: 0.6034\n",
      "[NDR] Epoch 120/1000  Train Loss: 0.4276  Val Loss: 0.5627\n",
      "[NDR] Epoch 140/1000  Train Loss: 0.4075  Val Loss: 0.5460\n",
      "[NDR] Epoch 160/1000  Train Loss: 0.3812  Val Loss: 0.5154\n",
      "[NDR] Epoch 180/1000  Train Loss: 0.3551  Val Loss: 0.5047\n",
      "[NDR] Epoch 200/1000  Train Loss: 0.3264  Val Loss: 0.4884\n",
      "[NDR] Epoch 220/1000  Train Loss: 0.3135  Val Loss: 0.4779\n",
      "[NDR] Epoch 240/1000  Train Loss: 0.2998  Val Loss: 0.4664\n",
      "[NDR] Epoch 260/1000  Train Loss: 0.2851  Val Loss: 0.4591\n",
      "[NDR] Epoch 280/1000  Train Loss: 0.2744  Val Loss: 0.4535\n",
      "[NDR] Epoch 300/1000  Train Loss: 0.2564  Val Loss: 0.4476\n",
      "[NDR] Epoch 320/1000  Train Loss: 0.2543  Val Loss: 0.4404\n",
      "[NDR] Epoch 340/1000  Train Loss: 0.2541  Val Loss: 0.4423\n",
      "[NDR] Epoch 360/1000  Train Loss: 0.2157  Val Loss: 0.4396\n",
      "[NDR] Epoch 380/1000  Train Loss: 0.2022  Val Loss: 0.4348\n",
      "[NDR] Epoch 400/1000  Train Loss: 0.2138  Val Loss: 0.4274\n",
      "[NDR] Epoch 420/1000  Train Loss: 0.1923  Val Loss: 0.4318\n",
      "[NDR] Epoch 440/1000  Train Loss: 0.1878  Val Loss: 0.4261\n",
      "[NDR] Epoch 460/1000  Train Loss: 0.1890  Val Loss: 0.4277\n",
      "[NDR] Epoch 480/1000  Train Loss: 0.1689  Val Loss: 0.4288\n",
      "[NDR] Epoch 500/1000  Train Loss: 0.1776  Val Loss: 0.4250\n",
      "[NDR] Epoch 520/1000  Train Loss: 0.1576  Val Loss: 0.4261\n",
      "[NDR] Early stopping at epoch 521 (patience=50)\n",
      "[NDR] Best @ epoch 471, Val Loss=0.4190\n",
      "[NDR] Saved best encoder to ./cancer_and_benign_pretrained/NDR_encoder_best.pth\n",
      "[NDR] Saved best full model to ./cancer_and_benign_pretrained/NDR_full_model_best.pth\n",
      "[NDR] Loss curves saved to ./cancer_and_benign_pretrained/NDR_256_epoch521_loss_curve.png\n",
      "Training Autoencoder for NDR2K...\n",
      "[NDR2K] Epoch 1/1000  Train Loss: 1.2506  Val Loss: 1.0224\n",
      "[NDR2K] Epoch 20/1000  Train Loss: 0.4400  Val Loss: 0.4873\n",
      "[NDR2K] Epoch 40/1000  Train Loss: 0.3802  Val Loss: 0.3848\n",
      "[NDR2K] Epoch 60/1000  Train Loss: 0.3386  Val Loss: 0.3297\n",
      "[NDR2K] Epoch 80/1000  Train Loss: 0.3258  Val Loss: 0.2823\n",
      "[NDR2K] Epoch 100/1000  Train Loss: 0.3092  Val Loss: 0.2589\n",
      "[NDR2K] Epoch 120/1000  Train Loss: 0.2953  Val Loss: 0.2515\n",
      "[NDR2K] Epoch 140/1000  Train Loss: 0.2824  Val Loss: 0.2457\n",
      "[NDR2K] Epoch 160/1000  Train Loss: 0.2641  Val Loss: 0.2497\n",
      "[NDR2K] Epoch 180/1000  Train Loss: 0.2556  Val Loss: 0.2385\n",
      "[NDR2K] Epoch 200/1000  Train Loss: 0.2477  Val Loss: 0.2411\n",
      "[NDR2K] Epoch 220/1000  Train Loss: 0.2550  Val Loss: 0.2354\n",
      "[NDR2K] Epoch 240/1000  Train Loss: 0.2346  Val Loss: 0.2313\n",
      "[NDR2K] Epoch 260/1000  Train Loss: 0.2221  Val Loss: 0.2278\n",
      "[NDR2K] Epoch 280/1000  Train Loss: 0.2129  Val Loss: 0.2260\n",
      "[NDR2K] Epoch 300/1000  Train Loss: 0.2071  Val Loss: 0.2215\n",
      "[NDR2K] Epoch 320/1000  Train Loss: 0.2074  Val Loss: 0.2216\n",
      "[NDR2K] Epoch 340/1000  Train Loss: 0.1918  Val Loss: 0.2238\n",
      "[NDR2K] Early stopping at epoch 360 (patience=50)\n",
      "[NDR2K] Best @ epoch 310, Val Loss=0.2188\n",
      "[NDR2K] Saved best encoder to ./cancer_and_benign_pretrained/NDR2K_encoder_best.pth\n",
      "[NDR2K] Saved best full model to ./cancer_and_benign_pretrained/NDR2K_full_model_best.pth\n",
      "[NDR2K] Loss curves saved to ./cancer_and_benign_pretrained/NDR2K_256_epoch360_loss_curve.png\n"
     ]
    }
   ],
   "source": [
    "%run encoder_pretrain.py \\\n",
    "    --modalities Frag CNV PFE NDR NDR2K \\\n",
    "    --data_file /home/maweicheng/database/cfDNA/cancer_and_benign/train.npz \\\n",
    "    --save_dir ./cancer_and_benign_pretrained \\\n",
    "    --epochs 1000 \\\n",
    "    --batch_size 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
