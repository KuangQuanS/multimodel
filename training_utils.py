"""
è®­ç»ƒå’Œè¯„ä¼°å·¥å…·å‡½æ•°
"""
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, SubsetRandomSampler
from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np
from torch.optim.lr_scheduler import CosineAnnealingLR
from tqdm import tqdm
from fusion_models import ModalityEncoder, CTModel
from dataset import get_modality_dimensions

# è®¾ç½®matplotlibä¸ºéäº¤äº’æ¨¡å¼ï¼Œå›¾ç‰‡ä¿å­˜åˆ°æ–‡ä»¶è€Œä¸æ˜¾ç¤º
plt.ioff()
plt.switch_backend('Agg')


class FocalLoss(nn.Module):
    """
    è®ºæ–‡: Focal Loss for Dense Object Detection (https://arxiv.org/abs/1708.02002)
    """
    
    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')

        p = F.softmax(inputs, dim=1)
        p_t = p.gather(1, targets.unsqueeze(1)).squeeze(1)

        focal_weight = (1 - p_t) ** self.gamma
        if isinstance(self.alpha, (list, np.ndarray, torch.Tensor)):
            if isinstance(self.alpha, (list, np.ndarray)):
                alpha_t = torch.tensor(self.alpha, device=inputs.device)[targets]
            else:
                alpha_t = self.alpha[targets]
        else:
            alpha_t = self.alpha
            
        focal_loss = alpha_t * focal_weight * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


def load_encoder(mod, checkpoint_dir=None, latent_dim=256, feature_dims=None):
    if feature_dims and mod in feature_dims:
        dim_in = feature_dims[mod]  # ä½¿ç”¨ç‰¹å¾é€‰æ‹©åçš„ç»´åº¦
    else:
        modality_dims = get_modality_dimensions()
        dim_in = modality_dims.get(mod, 1000)  # é»˜è®¤ç»´åº¦
    
    encoder = ModalityEncoder(dim_in=dim_in, dim_latent=latent_dim)

    return encoder


def train_epoch(model, encoders, loader, optimizer, criterion, device, l1_lambda=0.0):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    correct, total = 0, 0
    total_loss = 0.0
    num_batches = 0
    
    for batch in loader:
        optimizer.zero_grad()
        yb = batch['y'].to(device)
        
        modality_features = [encoders[mod](batch[f'X{i}'].to(device)) 
                           for i, mod in enumerate(encoders.keys()) if f'X{i}' in batch]
        
        zs = torch.stack(modality_features, dim=1)
        ct_data = batch.get('CT', None)
        ct_data = ct_data.to(device) if ct_data is not None else None
        
        logits = model(zs, ct_data)
        loss = criterion(logits, yb)
        
        # L1
        if l1_lambda > 0:
            l1_regularization = 0.0
            for param in model.parameters():
                l1_regularization += torch.sum(torch.abs(param))
            loss += l1_lambda * l1_regularization
            
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        num_batches += 1
        
        _, predicted = torch.max(logits.data, 1)
        total += yb.size(0)
        correct += (predicted == yb).sum().item()
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0
    accuracy = 100.0 * correct / total
    
    return accuracy, avg_loss


def evaluate(model, encoders, loader, device, criterion=None):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    # ç¡®ä¿æ‰€æœ‰ç¼–ç å™¨ä¹Ÿè®¾ç½®ä¸ºevalæ¨¡å¼
    for encoder in encoders.values():
        encoder.eval()
    
    all_preds, all_probs, all_labels = [], [], []
    error_cases = []
    total_loss = 0.0
    num_batches = 0

    with torch.no_grad():
        for batch in loader:
            yb = batch['y'].to(device)
            batch_size = yb.size(0)
            
            # å¤„ç†æ‰¹æ¬¡å¤§å°ä¸º1çš„æƒ…å†µï¼Œé¿å…BatchNormé”™è¯¯
            if batch_size == 1:
                # å¯¹äºå•æ ·æœ¬æ‰¹æ¬¡ï¼Œä½¿ç”¨evalæ¨¡å¼é¿å…BatchNormé—®é¢˜
                model.eval()
                for encoder in encoders.values():
                    encoder.eval()
            
            ids = batch.get('id', [f'sample_{i}' for i in range(len(yb))])
            modality_features = [encoders[mod](batch[f'X{i}'].to(device)) 
                               for i, mod in enumerate(encoders.keys()) if f'X{i}' in batch]
            
            zs = torch.stack(modality_features, dim=1)
            ct_data = batch.get('CT', None)
            ct_data = ct_data.to(device) if ct_data is not None else None
            
            try:
                logits = model(zs, ct_data)
            except RuntimeError as e:
                if "Expected more than 1 value per channel" in str(e):
                    print(f"âš ï¸  BatchNormé”™è¯¯ (batch_size={batch_size})ï¼Œè·³è¿‡è¯¥æ‰¹æ¬¡")
                    continue
                else:
                    raise e
            
            # è®¡ç®—æŸå¤±
            if criterion:
                loss = criterion(logits, yb)
                total_loss += loss.item()
                num_batches += 1
            probs = torch.softmax(logits, dim=1)
            preds = logits.argmax(1)

            # æ£€æŸ¥å¹¶å¤„ç†NaN/infå€¼
            probs_np = probs.cpu().numpy()
            if np.isnan(probs_np).any() or np.isinf(probs_np).any():
                print(f"âš ï¸  æ£€æµ‹åˆ°NaN/infæ¦‚ç‡å€¼ï¼Œè·³è¿‡è¯¥æ‰¹æ¬¡")
                continue
            
            all_preds.extend(preds.cpu().numpy())
            # ç¡®ä¿å–æ­£ç±»æ¦‚ç‡ï¼ˆå¦‚æœæ˜¯äºŒåˆ†ç±»ï¼‰
            if probs.shape[1] >= 2:
                all_probs.extend(probs[:, 1].cpu().numpy())
            else:
                all_probs.extend(probs[:, 0].cpu().numpy())
            all_labels.extend(yb.cpu().numpy())

            for i in range(len(yb)):
                if preds[i] != yb[i]:
                    error_cases.append({
                        'id': ids[i] if hasattr(ids, '__getitem__') else ids,
                        'true_label': yb[i].item(),
                        'pred_label': preds[i].item(),
                        'prob': probs[i, 1].item()
                    })
    
    # Calculate accuracy
    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))
    
    # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿æ²¡æœ‰NaNå€¼ä¼ å…¥AUCè®¡ç®—
    all_probs_clean = np.array(all_probs)
    all_labels_clean = np.array(all_labels)
    
    # å¦‚æœæœ‰NaNï¼Œç”¨0.5æ›¿æ¢ï¼ˆä¸­æ€§æ¦‚ç‡ï¼‰
    nan_mask = np.isnan(all_probs_clean) | np.isinf(all_probs_clean)
    if nan_mask.any():
        print(f"âš ï¸  å‘ç°å¹¶ä¿®å¤äº† {nan_mask.sum()} ä¸ªNaN/infæ¦‚ç‡å€¼")
        all_probs_clean[nan_mask] = 0.5
    
    try:
        auc_score = roc_auc_score(all_labels_clean, all_probs_clean)
    except ValueError as e:
        print(f"âš ï¸  AUCè®¡ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼0.5")
        auc_score = 0.5
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0
    
    return {
        'accuracy': accuracy,
        'f1': f1_score(all_labels, all_preds),
        'auc': auc_score,
        'loss': avg_loss,
        'preds': all_preds,
        'probs': all_probs_clean.tolist(),
        'labels': all_labels,
        'errors': error_cases
    }


def run_single_fold(model, encoders, train_loader, val_loader, args, fold=None, cv_dir=None):
    """è¿è¡Œå•æŠ˜è®­ç»ƒ"""
    cv_dir = cv_dir or os.path.join(args.output_dir, "cv_results")
    
    # Setup optimizer
    params = []
    params.extend(model.parameters())
    if args.finetune:
        params.extend([p for encoder in encoders.values() for p in encoder.parameters()])
    
    optimizer = optim.AdamW(params, lr=args.lr)

    T_max = max(1, args.epochs//3)  # ç¡®ä¿T_maxè‡³å°‘ä¸º1
    scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=args.lr/10)
    
    # Automatic class weight calculation (é»˜è®¤å¯ç”¨)
    auto_class_weights = getattr(args, 'auto_class_weights', True)  
    
    if auto_class_weights:
        # Calculate class weights based on training data distribution
        train_labels = []
        for batch in train_loader:
            train_labels.extend(batch['y'].cpu().numpy().tolist())  # Labels are in 'y' key
        
        # Count class frequencies
        from collections import Counter
        class_counts = Counter(train_labels)
        n_classes = len(class_counts)
        n_samples = len(train_labels)
        
        # Calculate inverse frequency weights: weight = n_samples / (n_classes * count)
        class_weights = []
        for i in range(n_classes):
            weight = n_samples / (n_classes * class_counts[i])
            class_weights.append(weight)
        
        print(f"Class distribution: {dict(class_counts)}")
        print(f"Auto-calculated class weights: {[f'{w:.3f}' for w in class_weights]}")
    
    # Create criterion - Focal Loss or CrossEntropyLoss
    if hasattr(args, 'use_focal_loss') and args.use_focal_loss:
        # Use Focal Loss for imbalanced data
        if auto_class_weights:
            alpha = torch.tensor(class_weights, dtype=torch.float32).to(args.device)
        elif hasattr(args, 'use_class_weights') and args.use_class_weights:
            alpha = torch.tensor(args.class_weights, dtype=torch.float32).to(args.device)
        else:
            alpha = args.focal_alpha if hasattr(args, 'focal_alpha') else 1.0
            
        gamma = args.focal_gamma if hasattr(args, 'focal_gamma') else 2.0
        criterion = FocalLoss(alpha=alpha, gamma=gamma)
        print(f"Using Focal Loss: alpha={alpha}, gamma={gamma}")
        
    elif auto_class_weights or (hasattr(args, 'use_class_weights') and args.use_class_weights):
        # Use CrossEntropyLoss with class weights (auto or manual)
        if auto_class_weights:
            weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(args.device)
        else:
            weights_tensor = torch.tensor(args.class_weights, dtype=torch.float32).to(args.device)
        
        criterion = nn.CrossEntropyLoss(weight=weights_tensor)
        print(f"Using weighted CrossEntropyLoss with weights: {[f'{w:.3f}' for w in weights_tensor.cpu().tolist()]}")
    else:
        # Standard CrossEntropyLoss
        criterion = nn.CrossEntropyLoss()
        print("Using standard CrossEntropyLoss (no class weights)")
    best_auc, best_epoch, best_results = 0, 0, None
    
    # Early stopping variables
    early_stopping_counter = 0
    use_early_stopping = hasattr(args, 'early_stopping') and args.early_stopping
    patience = getattr(args, 'patience', 10)
    min_delta = getattr(args, 'min_delta', 0.001)
    
    if use_early_stopping:
        print(f"Early stopping enabled: patience={patience}, min_delta={min_delta}")
    
    # Track training history
    train_losses, train_accs, val_losses, val_accs, val_f1s, val_aucs = [], [], [], [], [], []
    
    # æ·»åŠ tqdmè¿›åº¦æ¡
    fold_str = f" Fold {fold}" if fold is not None else ""
    epoch_range = tqdm(range(1, args.epochs + 1), 
                       desc=f"Training{fold_str}", 
                       unit="epoch",
                       leave=False)
    
    for epoch in epoch_range:
        train_acc, train_loss = train_epoch(model, encoders, train_loader, optimizer, criterion, args.device, args.l1_lambda)
        scheduler.step()
        
        # æ¯ä¸ªepochéƒ½è¯„ä¼°ï¼Œè·å¾—æ›´å¹³æ»‘çš„è®­ç»ƒæ›²çº¿
        val_results = evaluate(model, encoders, val_loader, args.device, criterion)
        
        # æ›´æ–°tqdmæè¿°ä¿¡æ¯
        epoch_range.set_postfix({
            'Train_Loss': f'{train_loss:.3f}',
            'Acc': f'{train_acc:.1f}%', 
            'Val_Loss': f'{val_results["loss"]:.3f}',
            'Val_AUC': f'{val_results["auc"]:.3f}'
        })
        
        # æ¯ä¸ªepochéƒ½è®°å½•è®­ç»ƒå†å²ï¼Œç¡®ä¿å¹³æ»‘æ›²çº¿
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        val_losses.append(val_results['loss'])  # æ·»åŠ éªŒè¯æŸå¤±è®°å½•
        val_accs.append(val_results['accuracy'])
        val_f1s.append(val_results['f1'])
        val_aucs.append(val_results['auc'])
        
        # Check for improvement and save best model
        if val_results['auc'] > best_auc + min_delta:
            best_auc = val_results['auc']
            best_epoch = epoch
            best_results = val_results
            early_stopping_counter = 0  # Reset counter on improvement
            
            model_path = os.path.join(cv_dir if fold else args.output_dir, 
                                    f"best_model{'_fold_'+str(fold) if fold else ''}.pth")
            torch.save(model.state_dict(), model_path)
            
                
        elif use_early_stopping:
            early_stopping_counter += 1
            if early_stopping_counter >= patience:
                epoch_range.set_description(f"Early Stop{fold_str}")
                break
    
    # Add training history to results
    if best_results:
        best_results['training_history'] = {
            'train_losses': train_losses,
            'train_accs': train_accs,
            'val_losses': val_losses,  # æ·»åŠ éªŒè¯æŸå¤±å†å²
            'val_accs': val_accs,
            'val_f1s': val_f1s,
            'val_aucs': val_aucs,
            'eval_epochs': list(range(1, len(train_losses) + 1))  # æ¯ä¸ªepochéƒ½æœ‰æ•°æ®
        }
    
    return best_results, best_epoch


def plot_training_curves(results, output_dir=None, fold=None, show=False):
    """
    ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„losså’ŒæŒ‡æ ‡æ›²çº¿
    
    Args:
        results: åŒ…å«training_historyçš„ç»“æœå­—å…¸
        output_dir: ä¿å­˜å›¾ç‰‡çš„ç›®å½•ï¼Œä¸ºNoneåˆ™ä¸ä¿å­˜
        fold: æŠ˜æ•°ï¼Œç”¨äºæ–‡ä»¶å‘½å
        show: æ˜¯å¦æ˜¾ç¤ºå›¾ç‰‡ (é»˜è®¤Falseï¼Œåªä¿å­˜åˆ°æ–‡ä»¶)
    """
    if 'training_history' not in results:
        print("Warning: No training history found in results")
        return
    
    history = results['training_history']
    epochs = history['eval_epochs']
    
    # åˆ›å»º2x2çš„å­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle(f'Training Curves{"" if fold is None else f" - Fold {fold}"}', fontsize=16)
    
    # Lossæ›²çº¿
    axes[0, 0].plot(epochs, history['train_losses'], 'b-', label='Train Loss', linewidth=2)
    if 'val_losses' in history:
        axes[0, 0].plot(epochs, history['val_losses'], 'r-', label='Val Loss', linewidth=2)
    axes[0, 0].set_title('Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].legend()
    
    # Accuracyæ›²çº¿
    axes[0, 1].plot(epochs, history['train_accs'], 'b-', label='Train Acc', linewidth=2)
    axes[0, 1].plot(epochs, history['val_accs'], 'r-', label='Val Acc', linewidth=2)
    axes[0, 1].set_title('Accuracy')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].legend()
    
    # F1åˆ†æ•°æ›²çº¿
    axes[1, 0].plot(epochs, history['val_f1s'], 'g-', label='Val F1', linewidth=2)
    axes[1, 0].set_title('F1 Score')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('F1 Score')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].legend()
    
    # AUCæ›²çº¿
    axes[1, 1].plot(epochs, history['val_aucs'], 'm-', label='Val AUC', linewidth=2)
    axes[1, 1].set_title('AUC Score')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('AUC')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].legend()
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    if output_dir:
        results_dir = os.path.join(output_dir, 'results')
        os.makedirs(results_dir, exist_ok=True)
        filename = f"training_curves{'_fold_'+str(fold) if fold else ''}.png"
        filepath = os.path.join(results_dir, filename)
        plt.savefig(filepath, dpi=150, bbox_inches='tight')
        print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {filepath}")
    
    # æ˜¾ç¤ºå›¾ç‰‡ (é»˜è®¤ä¸æ˜¾ç¤ºï¼Œåªä¿å­˜)
    if show:
        plt.show()
    else:
        plt.close()


def plot_all_folds_curves(all_results, output_dir=None):
    """
    ç»˜åˆ¶æ‰€æœ‰æŠ˜çš„è®­ç»ƒæ›²çº¿å¯¹æ¯”å›¾
    
    Args:
        all_results: åŒ…å«æ‰€æœ‰æŠ˜ç»“æœçš„åˆ—è¡¨
        output_dir: ä¿å­˜ç›®å½•
    """
    if not all_results or 'training_history' not in all_results[0]:
        print("Warning: No training history found in results")
        return
    
    # åˆ›å»º2x2çš„å­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Cross-Validation Training Curves', fontsize=16)
    
    colors = ['b', 'r', 'g', 'm', 'c', 'y', 'k', 'orange', 'purple', 'brown']
    
    for fold, results in enumerate(all_results):
        if 'training_history' not in results:
            continue
            
        history = results['training_history']
        epochs = history['eval_epochs']
        color = colors[fold % len(colors)]
        
        # Lossæ›²çº¿
        axes[0, 0].plot(epochs, history['train_losses'], color=color, 
                       alpha=0.7, label=f'Fold {fold+1}', linewidth=1.5)
        
        # Accuracyæ›²çº¿
        axes[0, 1].plot(epochs, history['val_accs'], color=color, 
                       alpha=0.7, label=f'Fold {fold+1}', linewidth=1.5)
        
        # F1æ›²çº¿
        axes[1, 0].plot(epochs, history['val_f1s'], color=color, 
                       alpha=0.7, label=f'Fold {fold+1}', linewidth=1.5)
        
        # AUCæ›²çº¿
        axes[1, 1].plot(epochs, history['val_aucs'], color=color, 
                       alpha=0.7, label=f'Fold {fold+1}', linewidth=1.5)
    
    # è®¾ç½®å­å›¾æ ‡é¢˜å’Œæ ‡ç­¾
    titles = ['Training Loss', 'Validation Accuracy', 'Validation F1', 'Validation AUC']
    ylabels = ['Loss', 'Accuracy', 'F1 Score', 'AUC']
    
    for i, (ax, title, ylabel) in enumerate(zip(axes.flat, titles, ylabels)):
        ax.set_title(title)
        ax.set_xlabel('Epoch')
        ax.set_ylabel(ylabel)
        ax.grid(True, alpha=0.3)
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    if output_dir:
        os.makedirs(os.path.join(output_dir, 'results'), exist_ok=True)
        filepath = os.path.join(output_dir, 'results', 'cross_validation_curves.png')
        plt.savefig(filepath, dpi=150, bbox_inches='tight')
        print(f"ğŸ“Š äº¤å‰éªŒè¯æ›²çº¿å·²ä¿å­˜: {filepath}")
    
    plt.show()


def plot_roc_curve(labels, probs, output_dir, suffix=""):
    """ç»˜åˆ¶ROCæ›²çº¿"""
    fpr, tpr, _ = roc_curve(labels, probs)
    roc_auc = auc(fpr, tpr)
    
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend(loc="lower right")
    
    roc_path = os.path.join(output_dir, f"roc_curve_{suffix}.png")
    plt.savefig(roc_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š ROCæ›²çº¿å·²ä¿å­˜: {roc_path}")


class CTFeatureExtractor(nn.Module):
    """CTç‰¹å¾æå–å™¨åŒ…è£…å™¨ï¼Œè¿”å›ç‰¹å¾è€Œä¸æ˜¯åˆ†ç±»ç»“æœ"""
    def __init__(self, ct_model):
        super().__init__()
        self.ct_model = ct_model
        
    def forward(self, x):
        # æå–ç‰¹å¾ï¼Œåœ¨MLPåˆ†ç±»å™¨ä¹‹å‰åœæ­¢
        x = self.ct_model.preBlock(x)
        x = self.ct_model.encoder(x)  
        x = self.ct_model.gap(x)  # è¾“å‡º [batch, 256*8*8]
        return x


def create_ct_model(ct_model_path, device, num_classes=2):
    """åˆ›å»ºå¹¶åŠ è½½CTæ¨¡å‹"""
    # ç›´æ¥ä½¿ç”¨æœ¬åœ°çš„CTModel
    ct_model = CTModel(num_classes=num_classes)
    
    if ct_model_path and os.path.exists(ct_model_path):
        try:
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            checkpoint = torch.load(ct_model_path, map_location=device, weights_only=True)
            if 'model_state_dict' in checkpoint:
                ct_model.load_state_dict(checkpoint['model_state_dict'])
            elif 'state_dict' in checkpoint:
                ct_model.load_state_dict(checkpoint['state_dict'])
            else:
                # ç›´æ¥åŠ è½½æƒé‡å­—å…¸
                ct_model.load_state_dict(checkpoint)
        except Exception as e:
            print("no pretrain CTmodel")
    
    # åŒ…è£…ä¸ºç‰¹å¾æå–å™¨
    ct_feature_extractor = CTFeatureExtractor(ct_model)
    return ct_feature_extractor.to(device)