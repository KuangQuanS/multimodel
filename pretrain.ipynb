{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3235509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder for Frag...\n",
      "[Frag] Epoch 1/1000  Train Loss: 0.2579  Val Loss: 0.1466\n",
      "[Frag] Epoch 20/1000  Train Loss: 0.0473  Val Loss: 0.0127\n",
      "[Frag] Epoch 40/1000  Train Loss: 0.0346  Val Loss: 0.0139\n",
      "[Frag] Epoch 60/1000  Train Loss: 0.0323  Val Loss: 0.0200\n",
      "[Frag] Early stopping at epoch 73 (patience=50)\n",
      "[Frag] Best @ epoch 23, Val Loss=0.0100\n",
      "[Frag] Saved best encoder to ./pretrained/Frag_encoder_best.pth\n",
      "[Frag] Saved best full model to ./pretrained/Frag_full_model_best.pth\n",
      "[Frag] Loss curves saved to ./pretrained/Frag_256_epoch73_loss_curve.png\n",
      "Training Autoencoder for CNV...\n",
      "[CNV] Epoch 1/1000  Train Loss: 1.0770  Val Loss: 0.9962\n",
      "[CNV] Epoch 20/1000  Train Loss: 0.1649  Val Loss: 0.0135\n",
      "[CNV] Epoch 40/1000  Train Loss: 0.1277  Val Loss: 0.0301\n",
      "[CNV] Epoch 60/1000  Train Loss: 0.1112  Val Loss: 0.0458\n",
      "[CNV] Epoch 80/1000  Train Loss: 0.0984  Val Loss: 0.0175\n",
      "[CNV] Epoch 100/1000  Train Loss: 0.1354  Val Loss: 0.0174\n",
      "[CNV] Epoch 120/1000  Train Loss: 0.1411  Val Loss: 0.0227\n",
      "[CNV] Epoch 140/1000  Train Loss: 0.0851  Val Loss: 0.0316\n",
      "[CNV] Epoch 160/1000  Train Loss: 0.0997  Val Loss: 0.0242\n",
      "[CNV] Epoch 180/1000  Train Loss: 0.1322  Val Loss: 0.0256\n",
      "[CNV] Epoch 200/1000  Train Loss: 0.1092  Val Loss: 0.0213\n",
      "[CNV] Epoch 220/1000  Train Loss: 0.1095  Val Loss: 0.0278\n",
      "[CNV] Epoch 240/1000  Train Loss: 0.0492  Val Loss: 0.0244\n",
      "[CNV] Early stopping at epoch 242 (patience=50)\n",
      "[CNV] Best @ epoch 192, Val Loss=0.0109\n",
      "[CNV] Saved best encoder to ./pretrained/CNV_encoder_best.pth\n",
      "[CNV] Saved best full model to ./pretrained/CNV_full_model_best.pth\n",
      "[CNV] Loss curves saved to ./pretrained/CNV_256_epoch242_loss_curve.png\n",
      "Training Autoencoder for PFE...\n",
      "[PFE] Epoch 1/1000  Train Loss: 0.3395  Val Loss: 0.2000\n",
      "[PFE] Epoch 20/1000  Train Loss: 0.0429  Val Loss: 0.0346\n",
      "[PFE] Epoch 40/1000  Train Loss: 0.0370  Val Loss: 0.0529\n",
      "[PFE] Epoch 60/1000  Train Loss: 0.0379  Val Loss: 0.0338\n",
      "[PFE] Epoch 80/1000  Train Loss: 0.0262  Val Loss: 0.0287\n",
      "[PFE] Epoch 100/1000  Train Loss: 0.0251  Val Loss: 0.0635\n",
      "[PFE] Early stopping at epoch 120 (patience=50)\n",
      "[PFE] Best @ epoch 70, Val Loss=0.0074\n",
      "[PFE] Saved best encoder to ./pretrained/PFE_encoder_best.pth\n",
      "[PFE] Saved best full model to ./pretrained/PFE_full_model_best.pth\n",
      "[PFE] Loss curves saved to ./pretrained/PFE_256_epoch120_loss_curve.png\n",
      "Training Autoencoder for NDR...\n",
      "[NDR] Epoch 1/1000  Train Loss: 1.7575  Val Loss: 1.3505\n",
      "[NDR] Epoch 20/1000  Train Loss: 1.0463  Val Loss: 0.6806\n",
      "[NDR] Epoch 40/1000  Train Loss: 0.9019  Val Loss: 0.6104\n",
      "[NDR] Epoch 60/1000  Train Loss: 0.7212  Val Loss: 0.5723\n",
      "[NDR] Epoch 80/1000  Train Loss: 0.7013  Val Loss: 0.5479\n",
      "[NDR] Epoch 100/1000  Train Loss: 0.6494  Val Loss: 0.5163\n",
      "[NDR] Epoch 120/1000  Train Loss: 0.6149  Val Loss: 0.5085\n",
      "[NDR] Epoch 140/1000  Train Loss: 0.5888  Val Loss: 0.4938\n",
      "[NDR] Epoch 160/1000  Train Loss: 0.6370  Val Loss: 0.4919\n",
      "[NDR] Epoch 180/1000  Train Loss: 0.5269  Val Loss: 0.4651\n",
      "[NDR] Epoch 200/1000  Train Loss: 0.5535  Val Loss: 0.4552\n",
      "[NDR] Epoch 220/1000  Train Loss: 0.5641  Val Loss: 0.4492\n",
      "[NDR] Epoch 240/1000  Train Loss: 0.5084  Val Loss: 0.4437\n",
      "[NDR] Epoch 260/1000  Train Loss: 0.4899  Val Loss: 0.4283\n",
      "[NDR] Epoch 280/1000  Train Loss: 0.5102  Val Loss: 0.4258\n",
      "[NDR] Epoch 300/1000  Train Loss: 0.4456  Val Loss: 0.4187\n",
      "[NDR] Epoch 320/1000  Train Loss: 0.4169  Val Loss: 0.4063\n",
      "[NDR] Epoch 340/1000  Train Loss: 0.4127  Val Loss: 0.4054\n",
      "[NDR] Epoch 360/1000  Train Loss: 0.5695  Val Loss: 0.4044\n",
      "[NDR] Epoch 380/1000  Train Loss: 0.3738  Val Loss: 0.3827\n",
      "[NDR] Epoch 400/1000  Train Loss: 0.5043  Val Loss: 0.3854\n",
      "[NDR] Epoch 420/1000  Train Loss: 0.3661  Val Loss: 0.3783\n",
      "[NDR] Epoch 440/1000  Train Loss: 0.3545  Val Loss: 0.3689\n",
      "[NDR] Epoch 460/1000  Train Loss: 0.6076  Val Loss: 0.3822\n",
      "[NDR] Epoch 480/1000  Train Loss: 0.4632  Val Loss: 0.3694\n",
      "[NDR] Epoch 500/1000  Train Loss: 0.3339  Val Loss: 0.3532\n",
      "[NDR] Epoch 520/1000  Train Loss: 0.3373  Val Loss: 0.3584\n",
      "[NDR] Epoch 540/1000  Train Loss: 0.3286  Val Loss: 0.3510\n",
      "[NDR] Epoch 560/1000  Train Loss: 0.3705  Val Loss: 0.3482\n",
      "[NDR] Epoch 580/1000  Train Loss: 0.2986  Val Loss: 0.3355\n",
      "[NDR] Epoch 600/1000  Train Loss: 0.3010  Val Loss: 0.3382\n",
      "[NDR] Epoch 620/1000  Train Loss: 0.3002  Val Loss: 0.3460\n",
      "[NDR] Epoch 640/1000  Train Loss: 0.3219  Val Loss: 0.3463\n",
      "[NDR] Epoch 660/1000  Train Loss: 0.2867  Val Loss: 0.3317\n",
      "[NDR] Epoch 680/1000  Train Loss: 0.2768  Val Loss: 0.3279\n",
      "[NDR] Epoch 700/1000  Train Loss: 0.2809  Val Loss: 0.3312\n",
      "[NDR] Epoch 720/1000  Train Loss: 0.3535  Val Loss: 0.3345\n",
      "[NDR] Epoch 740/1000  Train Loss: 0.3011  Val Loss: 0.3310\n",
      "[NDR] Epoch 760/1000  Train Loss: 0.2537  Val Loss: 0.3225\n",
      "[NDR] Epoch 780/1000  Train Loss: 0.2409  Val Loss: 0.3217\n",
      "[NDR] Epoch 800/1000  Train Loss: 0.3430  Val Loss: 0.3307\n",
      "[NDR] Epoch 820/1000  Train Loss: 0.2288  Val Loss: 0.3150\n",
      "[NDR] Early stopping at epoch 835 (patience=50)\n",
      "[NDR] Best @ epoch 785, Val Loss=0.3122\n",
      "[NDR] Saved best encoder to ./pretrained/NDR_encoder_best.pth\n",
      "[NDR] Saved best full model to ./pretrained/NDR_full_model_best.pth\n",
      "[NDR] Loss curves saved to ./pretrained/NDR_256_epoch835_loss_curve.png\n",
      "Training Autoencoder for NDR2K...\n",
      "[NDR2K] Epoch 1/1000  Train Loss: 1.3575  Val Loss: 1.1416\n",
      "[NDR2K] Epoch 20/1000  Train Loss: 0.4740  Val Loss: 0.4185\n",
      "[NDR2K] Epoch 40/1000  Train Loss: 0.4129  Val Loss: 0.3563\n",
      "[NDR2K] Epoch 60/1000  Train Loss: 0.4593  Val Loss: 0.3547\n",
      "[NDR2K] Epoch 80/1000  Train Loss: 0.3727  Val Loss: 0.3289\n",
      "[NDR2K] Epoch 100/1000  Train Loss: 0.3510  Val Loss: 0.3171\n",
      "[NDR2K] Epoch 120/1000  Train Loss: 0.3898  Val Loss: 0.3080\n",
      "[NDR2K] Epoch 140/1000  Train Loss: 0.3221  Val Loss: 0.3086\n",
      "[NDR2K] Epoch 160/1000  Train Loss: 0.3844  Val Loss: 0.3040\n",
      "[NDR2K] Epoch 180/1000  Train Loss: 0.3205  Val Loss: 0.2841\n",
      "[NDR2K] Epoch 200/1000  Train Loss: 0.4495  Val Loss: 0.2856\n",
      "[NDR2K] Epoch 220/1000  Train Loss: 0.3064  Val Loss: 0.2825\n",
      "[NDR2K] Epoch 240/1000  Train Loss: 0.4919  Val Loss: 0.2831\n",
      "[NDR2K] Epoch 260/1000  Train Loss: 0.2820  Val Loss: 0.2686\n",
      "[NDR2K] Epoch 280/1000  Train Loss: 0.2755  Val Loss: 0.2666\n",
      "[NDR2K] Epoch 300/1000  Train Loss: 0.3069  Val Loss: 0.2585\n",
      "[NDR2K] Epoch 320/1000  Train Loss: 0.2847  Val Loss: 0.2654\n",
      "[NDR2K] Epoch 340/1000  Train Loss: 0.4158  Val Loss: 0.2681\n",
      "[NDR2K] Epoch 360/1000  Train Loss: 0.2974  Val Loss: 0.2616\n",
      "[NDR2K] Epoch 380/1000  Train Loss: 0.2424  Val Loss: 0.2486\n",
      "[NDR2K] Epoch 400/1000  Train Loss: 0.2404  Val Loss: 0.2429\n",
      "[NDR2K] Epoch 420/1000  Train Loss: 0.2566  Val Loss: 0.2458\n",
      "[NDR2K] Epoch 440/1000  Train Loss: 0.2316  Val Loss: 0.2388\n",
      "[NDR2K] Epoch 460/1000  Train Loss: 0.2308  Val Loss: 0.2336\n",
      "[NDR2K] Epoch 480/1000  Train Loss: 0.2139  Val Loss: 0.2340\n",
      "[NDR2K] Epoch 500/1000  Train Loss: 0.2495  Val Loss: 0.2414\n",
      "[NDR2K] Epoch 520/1000  Train Loss: 0.2175  Val Loss: 0.2269\n",
      "[NDR2K] Epoch 540/1000  Train Loss: 0.1984  Val Loss: 0.2258\n",
      "[NDR2K] Epoch 560/1000  Train Loss: 0.2570  Val Loss: 0.2210\n",
      "[NDR2K] Epoch 580/1000  Train Loss: 0.1910  Val Loss: 0.2169\n",
      "[NDR2K] Epoch 600/1000  Train Loss: 0.1804  Val Loss: 0.2110\n",
      "[NDR2K] Epoch 620/1000  Train Loss: 0.1923  Val Loss: 0.2183\n",
      "[NDR2K] Epoch 640/1000  Train Loss: 0.1772  Val Loss: 0.2094\n",
      "[NDR2K] Epoch 660/1000  Train Loss: 0.2031  Val Loss: 0.2072\n",
      "[NDR2K] Epoch 680/1000  Train Loss: 0.1531  Val Loss: 0.2093\n",
      "[NDR2K] Epoch 700/1000  Train Loss: 0.1474  Val Loss: 0.2005\n",
      "[NDR2K] Epoch 720/1000  Train Loss: 0.1605  Val Loss: 0.1993\n",
      "[NDR2K] Epoch 740/1000  Train Loss: 0.1523  Val Loss: 0.1941\n",
      "[NDR2K] Epoch 760/1000  Train Loss: 0.1482  Val Loss: 0.1928\n",
      "[NDR2K] Epoch 780/1000  Train Loss: 0.1475  Val Loss: 0.1953\n",
      "[NDR2K] Epoch 800/1000  Train Loss: 0.1611  Val Loss: 0.1970\n",
      "[NDR2K] Epoch 820/1000  Train Loss: 0.1705  Val Loss: 0.1915\n",
      "[NDR2K] Epoch 840/1000  Train Loss: 0.1310  Val Loss: 0.1846\n",
      "[NDR2K] Epoch 860/1000  Train Loss: 0.1316  Val Loss: 0.1774\n",
      "[NDR2K] Epoch 880/1000  Train Loss: 0.1307  Val Loss: 0.1899\n",
      "[NDR2K] Early stopping at epoch 883 (patience=50)\n",
      "[NDR2K] Best @ epoch 833, Val Loss=0.1757\n",
      "[NDR2K] Saved best encoder to ./pretrained/NDR2K_encoder_best.pth\n",
      "[NDR2K] Saved best full model to ./pretrained/NDR2K_full_model_best.pth\n",
      "[NDR2K] Loss curves saved to ./pretrained/NDR2K_256_epoch883_loss_curve.png\n"
     ]
    }
   ],
   "source": [
    "%run pretrain.py \\\n",
    "    --modalities Frag CNV PFE NDR NDR2K \\\n",
    "    --data_file ../database/cfDNA/train/multimodal_data.npz \\\n",
    "    --epochs 1000 \\\n",
    "    --batch_size 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
