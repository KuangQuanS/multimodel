{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59d1258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Cls=0.0546 | Dom=1.6207 | Acc=98.89% | ValAcc=95.56% | F1=0.9446\n",
      "🎉find best f1 0.9446,epoch: 50\n",
      "Epoch 100: Cls=0.0188 | Dom=1.6117 | Acc=99.72% | ValAcc=96.67% | F1=0.9590\n",
      "🎉find best f1 0.9590,epoch: 100\n",
      "Epoch 150: Cls=0.0320 | Dom=1.6149 | Acc=99.44% | ValAcc=95.56% | F1=0.9459\n",
      "Epoch 200: Cls=0.0015 | Dom=1.6062 | Acc=100.00% | ValAcc=95.56% | F1=0.9459\n",
      "Epoch 250: Cls=0.0072 | Dom=1.6077 | Acc=99.72% | ValAcc=95.56% | F1=0.9459\n",
      "Epoch 300: Cls=0.0398 | Dom=1.6088 | Acc=99.17% | ValAcc=95.56% | F1=0.9459\n",
      "Epoch 350: Cls=0.0597 | Dom=1.6069 | Acc=97.78% | ValAcc=94.44% | F1=0.9331\n",
      "Epoch 400: Cls=0.0010 | Dom=1.6088 | Acc=100.00% | ValAcc=95.56% | F1=0.9459\n",
      "Epoch 450: Cls=0.0001 | Dom=1.6084 | Acc=100.00% | ValAcc=95.56% | F1=0.9459\n",
      "Epoch 500: Cls=0.0001 | Dom=1.6107 | Acc=100.00% | ValAcc=95.56% | F1=0.9459\n",
      "✅ Saved fusion_with_domain.pth\n"
     ]
    }
   ],
   "source": [
    "%run finetune_noct.py --modalities Frag CNV PFE NDR NDR2K --data_file ../database/cfDNA/multimodal_data.npz --epochs 500 --finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da7521",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "# 不使用对抗学习，即不消除五种之间的差距，一点用没有啊，大哭😭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a84c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Cls=0.0510 | Dom=1.6071 | Acc=98.61% | ValAcc=95.56% | F1=0.9446\n",
      "🎉find best f1 0.9446,epoch: 50\n",
      "Epoch 100: Cls=0.0032 | Dom=1.6181 | Acc=100.00% | ValAcc=95.56% | F1=0.9459\n",
      "🎉find best f1 0.9459,epoch: 100\n",
      "Epoch 150: Cls=0.0028 | Dom=1.6173 | Acc=99.72% | ValAcc=96.67% | F1=0.9590\n",
      "🎉find best f1 0.9590,epoch: 150\n",
      "Epoch 200: Cls=0.0002 | Dom=1.6163 | Acc=100.00% | ValAcc=96.67% | F1=0.9590\n",
      "Epoch 250: Cls=0.0091 | Dom=1.6174 | Acc=99.72% | ValAcc=96.67% | F1=0.9590\n",
      "Epoch 300: Cls=0.0071 | Dom=1.6183 | Acc=99.72% | ValAcc=94.44% | F1=0.9331\n",
      "Epoch 350: Cls=0.0002 | Dom=1.6212 | Acc=100.00% | ValAcc=94.44% | F1=0.9316\n",
      "Epoch 400: Cls=0.0008 | Dom=1.6233 | Acc=100.00% | ValAcc=95.56% | F1=0.9446\n",
      "Epoch 450: Cls=0.0025 | Dom=1.6235 | Acc=99.72% | ValAcc=94.44% | F1=0.9316\n",
      "Epoch 500: Cls=0.0001 | Dom=1.6254 | Acc=100.00% | ValAcc=94.44% | F1=0.9316\n",
      "✅ Saved fusion_with_domain.pth\n"
     ]
    }
   ],
   "source": [
    "%run finetune_noct.py --modalities Frag CNV PFE NDR NDR2K --data_file ../database/cfDNA/multimodal_data.npz --epochs 500 --finetune --domain_weight 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5973df29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maweicheng/multimodel/finetune_noct.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Frag] Epoch 10: TrainAcc=76.39% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 20: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 30: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 40: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 50: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 60: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 70: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 80: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 90: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 100: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 110: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 120: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 130: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 140: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 150: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 160: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 170: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 180: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 190: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 200: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 210: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 220: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 230: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 240: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 250: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 260: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 270: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 280: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 290: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 300: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 310: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 320: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 330: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 340: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 350: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 360: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 370: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 380: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n",
      "[Frag] Epoch 390: TrainAcc=76.67% ValAcc=71.11% | F1=0.4156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/multimodel/finetune_noct.py:364\u001b[0m\n\u001b[1;32m    362\u001b[0m p\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--lambda_schedule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, choices\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m],help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda衰减策略\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    363\u001b[0m args \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_args()\n\u001b[0;32m--> 364\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/multimodel/finetune_noct.py:153\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    151\u001b[0m clf\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    152\u001b[0m total \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Xb, yb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    154\u001b[0m     Xb, yb \u001b[38;5;241m=\u001b[39m Xb\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice), yb\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# 编码\u001b[39;00m\n",
      "File \u001b[0;32m/softwares/miniconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/softwares/miniconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/softwares/miniconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/softwares/miniconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/softwares/miniconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/softwares/miniconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run finetune_noct.py --data_file ../database/cfDNA/multimodal_data.npz --epochs 500 --finetune --single_mod Frag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
